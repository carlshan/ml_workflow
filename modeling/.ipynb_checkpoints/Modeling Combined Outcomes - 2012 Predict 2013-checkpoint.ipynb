{
 "metadata": {
  "name": "",
  "signature": "sha256:8c5ceda5b26c64a7018975d1507847888c9ac9906dd16b9078e819c141942f0f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Last modified: 12/09/2014 by Carl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import classification\n",
      "import matplotlib.pylab as pl\n",
      "import sys\n",
      "sys.path.append('../etl/')\n",
      "import util\n",
      "import diagnostics\n",
      "from pprint import pprint\n",
      "from sklearn import tree\n",
      "from diagnostics import get_feature_importances\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing, decomposition\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import precision_recall_curve, auc\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "pd.options.display.mpl_style = 'default'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_path = 's3://dsapp-edu-data/NC-Cabarrus/cleaned_data/'\n",
      "data_filename = 'master_10_17_2014.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setting low_memory=False allows more accurate type inference as python loads\n",
      "# the csv\n",
      "data = pd.read_csv(data_path+data_filename, low_memory=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(28604, 248)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>External_Student_ID</th>\n",
        "      <th>earliest_reporting_year</th>\n",
        "      <th>earliest_recorded_grade</th>\n",
        "      <th>expected_graduating_year</th>\n",
        "      <th>retained</th>\n",
        "      <th>grades_retained</th>\n",
        "      <th>retained_in_8</th>\n",
        "      <th>retained_in_9</th>\n",
        "      <th>retained_in_10</th>\n",
        "      <th>retained_in_11</th>\n",
        "      <th>...</th>\n",
        "      <th>Wcode_dropout</th>\n",
        "      <th>Reason_dropout</th>\n",
        "      <th>retained_in_8_majority_vote</th>\n",
        "      <th>retained_in_9_majority_vote</th>\n",
        "      <th>retained_in_10_majority_vote</th>\n",
        "      <th>retained_in_11_majority_vote</th>\n",
        "      <th>retained_in_12_majority_vote</th>\n",
        "      <th>graduated_on_time_majority_vote</th>\n",
        "      <th>transferred_out_before_graduating</th>\n",
        "      <th>fail_to_finish_high_school_in_4_years</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 8</td>\n",
        "      <td> 2015</td>\n",
        "      <td> 1</td>\n",
        "      <td> ['9']</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>  W2</td>\n",
        "      <td> LTSU</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1003</td>\n",
        "      <td> 2008</td>\n",
        "      <td> 9</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 0</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1004</td>\n",
        "      <td> 2009</td>\n",
        "      <td> 9</td>\n",
        "      <td> 2012</td>\n",
        "      <td> 1</td>\n",
        "      <td> ['9']</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1005</td>\n",
        "      <td> 2008</td>\n",
        "      <td> 9</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 0</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1006</td>\n",
        "      <td> 2010</td>\n",
        "      <td> 8</td>\n",
        "      <td> 2014</td>\n",
        "      <td> 0</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 248 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   External_Student_ID  earliest_reporting_year  earliest_recorded_grade  \\\n",
        "0                 1002                     2011                        8   \n",
        "1                 1003                     2008                        9   \n",
        "2                 1004                     2009                        9   \n",
        "3                 1005                     2008                        9   \n",
        "4                 1006                     2010                        8   \n",
        "\n",
        "   expected_graduating_year  retained grades_retained  retained_in_8  \\\n",
        "0                      2015         1           ['9']              0   \n",
        "1                      2011         0             NaN              0   \n",
        "2                      2012         1           ['9']              0   \n",
        "3                      2011         0             NaN              0   \n",
        "4                      2014         0             NaN              0   \n",
        "\n",
        "   retained_in_9  retained_in_10  retained_in_11  \\\n",
        "0              1               0               0   \n",
        "1              0               0               0   \n",
        "2              1               0               0   \n",
        "3              0               0               0   \n",
        "4              0               0               0   \n",
        "\n",
        "                   ...                    Wcode_dropout  Reason_dropout  \\\n",
        "0                  ...                               W2            LTSU   \n",
        "1                  ...                              NaN             NaN   \n",
        "2                  ...                              NaN             NaN   \n",
        "3                  ...                              NaN             NaN   \n",
        "4                  ...                              NaN             NaN   \n",
        "\n",
        "   retained_in_8_majority_vote  retained_in_9_majority_vote  \\\n",
        "0                            0                            1   \n",
        "1                            0                            0   \n",
        "2                            0                            1   \n",
        "3                            0                            0   \n",
        "4                            0                            0   \n",
        "\n",
        "   retained_in_10_majority_vote  retained_in_11_majority_vote  \\\n",
        "0                             0                             0   \n",
        "1                             0                             0   \n",
        "2                             0                             0   \n",
        "3                             0                             0   \n",
        "4                             0                             0   \n",
        "\n",
        "  retained_in_12_majority_vote  graduated_on_time_majority_vote  \\\n",
        "0                            0                                0   \n",
        "1                            0                                1   \n",
        "2                            0                                0   \n",
        "3                            0                                0   \n",
        "4                            0                                1   \n",
        "\n",
        "   transferred_out_before_graduating  fail_to_finish_high_school_in_4_years  \n",
        "0                                  0                                      1  \n",
        "1                                  0                                      0  \n",
        "2                                  1                                      1  \n",
        "3                                  1                                      1  \n",
        "4                                  0                                      0  \n",
        "\n",
        "[5 rows x 248 columns]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dropout_data = pd.read_csv(data_path + 'Dropout_Data_0708_1213_20141001_clean_2014_10_1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dropout_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(1943, 10)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include_cols = [\n",
      " 'External_Student_ID',\n",
      " 'Grade_8th_grade',\n",
      " 'STATE_12th_grade',\n",
      " 'STATE_11th_grade',\n",
      " 'eds_8th_grade',\n",
      " 'GPA_Math_11th_grade',\n",
      " 'GPA_Math_12th_grade',\n",
      " 'GPA_Math_9th_grade',\n",
      " 'GPA_Math_10th_grade',\n",
      " 'swd_8th_grade',\n",
      " 'Street_8th_grade',\n",
      " 'CITY_10th_grade',\n",
      " 'NumAdvanced_8th_grade',\n",
      " 'CITY_9th_grade',\n",
      " 'STATE_10th_grade',\n",
      "#  'grade_11th_grade',\n",
      " 'STATE_9th_grade',\n",
      " 'lep_8th_grade',\n",
      " 'GPA_SocSci_9th_grade',\n",
      "#  'Grade_11th_grade',\n",
      " 'GPA_SocSci_10th_grade',\n",
      " 'reporting_year_8th_grade',\n",
      " 'Street_11th_grade',\n",
      " 'Street_12th_grade',\n",
      " 'GPA_Science_8th_grade',\n",
      " 'sex_11th_grade',\n",
      " 'GPA_Science_12th_grade',\n",
      " 'sex_9th_grade',\n",
      " 'sex_10th_grade',\n",
      " 'Num_Marks_8th_grade',\n",
      " 'daysabs_10th_grade',\n",
      " 'daysabs_9th_grade',\n",
      " 'NumAdvanced_SocSci_8th_grade',\n",
      " 'times_tardy_8th_grade',\n",
      " 'lep_11th_grade',\n",
      " 'lep_10th_grade',\n",
      " 'lep_9th_grade',\n",
      " 'sex_8th_grade',\n",
      " 'Street_9th_grade',\n",
      " 'Street_10th_grade',\n",
      " 'Grade_12th_grade',\n",
      "#  'Grade_10th_grade',\n",
      " 'Grade_9th_grade',\n",
      " 'GPA_Science_10th_grade',\n",
      " 'GPA_Science_9th_grade',\n",
      " 'GPA_Science_11th_grade',\n",
      " 'GPA_9th_grade',\n",
      " 'GPA_10th_grade',\n",
      " 'GPA_11th_grade',\n",
      " 'GPA_12th_grade',\n",
      " 'NumAdvanced_SocSci_11th_grade',\n",
      " 'Num_Science_8th_grade',\n",
      " 'NumAdvanced_SocSci_9th_grade',\n",
      " 'NumAdvanced_SocSci_10th_grade',\n",
      " 'GPA_SocSci_8th_grade',\n",
      " 'reporting_year_10th_grade',\n",
      " 'reporting_year_9th_grade',\n",
      " 'CITY_8th_grade',\n",
      " 'eds_10th_grade',\n",
      " 'eds_11th_grade',\n",
      " 'grade_8th_grade',\n",
      " 'Num_SocSci_8th_grade',\n",
      " 'GPA_ENG_8th_grade',\n",
      " 'Num_Marks_10th_grade',\n",
      " 'Num_Marks_9th_grade',\n",
      " 'Num_Marks_12th_grade',\n",
      " 'Num_Marks_11th_grade',\n",
      " 'NumAdvanced_Science_8th_grade',\n",
      " 'Num_Science_12th_grade',\n",
      " 'Num_Science_11th_grade',\n",
      " 'Num_Science_10th_grade',\n",
      " 'Num_Science_9th_grade',\n",
      " 'GPA_SocSci_11th_grade',\n",
      " 'GPA_SocSci_12th_grade',\n",
      " 'GPA_8th_grade',\n",
      " 'NumAdvanced_ENG_8th_grade',\n",
      " 'reporting_year_11th_grade',\n",
      "#  'grade_10th_grade',\n",
      "#  'grade_9th_grade',\n",
      " 'exc_abs_8th_grade',\n",
      " 'daysabs_8th_grade',\n",
      " 'Num_ENG_8th_grade',\n",
      " 'Num_SocSci_9th_grade',\n",
      " 'Num_SocSci_10th_grade',\n",
      " 'Num_SocSci_11th_grade',\n",
      " 'Num_SocSci_12th_grade',\n",
      " 'GPA_ENG_12th_grade',\n",
      " 'GPA_ENG_11th_grade',\n",
      " 'GPA_ENG_10th_grade',\n",
      " 'GPA_ENG_9th_grade',\n",
      " 'ZIP_8th_grade',\n",
      " 'NumAdvanced_Science_10th_grade',\n",
      " 'NumAdvanced_Science_12th_grade',\n",
      " 'NumAdvanced_Science_11th_grade',\n",
      " 'times_tardy_11th_grade',\n",
      " 'times_tardy_10th_grade',\n",
      " 'times_tardy_9th_grade',\n",
      " 'NumAdvanced_ENG_12th_grade',\n",
      " 'NumAdvanced_ENG_11th_grade',\n",
      " 'NumAdvanced_ENG_10th_grade',\n",
      " 'NumAdvanced_ENG_9th_grade',\n",
      " 'ZIP_12th_grade',\n",
      " 'ethnic_8th_grade',\n",
      " 'CITY_11th_grade',\n",
      " 'CITY_12th_grade',\n",
      " 'Num_ENG_10th_grade',\n",
      " 'Num_ENG_9th_grade',\n",
      " 'Num_ENG_12th_grade',\n",
      " 'Num_ENG_11th_grade',\n",
      " 'daysabs_11th_grade',\n",
      " 'Num_Math_8th_grade',\n",
      " 'eds_9th_grade',\n",
      " 'unexc_abs_9th_grade',\n",
      " 'unexc_abs_10th_grade',\n",
      " 'unexc_abs_11th_grade',\n",
      " 'ZIP_10th_grade',\n",
      " 'ZIP_9th_grade',\n",
      " 'ZIP_11th_grade',\n",
      " 'NumAdvanced_Math_11th_grade',\n",
      " 'NumAdvanced_Math_12th_grade',\n",
      " 'NumAdvanced_Math_9th_grade',\n",
      " 'NumAdvanced_Math_10th_grade',\n",
      " 'NumAdvanced_SocSci_12th_grade',\n",
      " 'Num_Math_9th_grade',\n",
      " 'Num_Math_10th_grade',\n",
      " 'Num_Math_11th_grade',\n",
      " 'Num_Math_12th_grade',\n",
      " 'school_code_11th_grade',\n",
      " 'school_code_9th_grade',\n",
      " 'ethnic_11th_grade',\n",
      " 'ethnic_9th_grade',\n",
      " 'ethnic_10th_grade',\n",
      " 'exc_abs_9th_grade',\n",
      " 'unexc_abs_8th_grade',\n",
      " 'STATE_8th_grade',\n",
      " 'NumAdvanced_Math_8th_grade',\n",
      " 'exc_abs_11th_grade',\n",
      " 'exc_abs_10th_grade',\n",
      " 'NumAdvanced_Science_9th_grade',\n",
      " 'school_code_10th_grade',\n",
      " 'GPA_Math_8th_grade',\n",
      " 'swd_9th_grade',\n",
      " 'swd_10th_grade',\n",
      " 'swd_11th_grade',\n",
      " 'school_code_8th_grade',\n",
      " 'NumAdvanced_9th_grade',\n",
      " 'NumAdvanced_10th_grade',\n",
      " 'NumAdvanced_11th_grade',\n",
      " 'NumAdvanced_12th_grade',\n",
      " 'earliest_reporting_year_majority_vote',\n",
      " 'earliest_recorded_grade_majority_vote',\n",
      " 'retained_in_8_majority_vote',\n",
      " 'retained_in_9_majority_vote',\n",
      " 'retained_in_10_majority_vote',\n",
      " 'retained_in_11_majority_vote',\n",
      " 'retained_in_12_majority_vote',\n",
      " 'expected_graduation_year_majority_vote',\n",
      " 'Grade_dropout',\n",
      " 'dropout_outcome',\n",
      " 'fail_to_finish_high_school_in_4_years',\n",
      " 'transferred_out_before_graduating',]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cohort_a = data[data['expected_graduation_year_majority_vote'] == 2012]\n",
      "cohort_b = data[data['expected_graduation_year_majority_vote'] == 2013]\n",
      "cohort_c = data[data['expected_graduation_year_majority_vote'] == 2014]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cohort_a.shape[0], sum(cohort_a['dropout_outcome'])\n",
      "print cohort_b.shape[0], sum(cohort_b['dropout_outcome'])\n",
      "print cohort_c.shape[0], sum(cohort_c['dropout_outcome'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2866 224\n",
        "2917 198\n",
        "2903 116\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "renamed_a = cohort_a.rename(columns=\n",
      "                            util.make_rename_col_dict(cohort_a.columns, 2012))[include_cols]\n",
      "renamed_b = cohort_b.rename(columns=\n",
      "                            util.make_rename_col_dict(cohort_b.columns, 2013))[include_cols]\n",
      "renamed_c = cohort_c.rename(columns=\n",
      "                            util.make_rename_col_dict(cohort_c.columns, 2014))[include_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Roughly 8% of 9th grade students in the class of 2012 drop out of\n",
      "# high school.\n",
      "renamed_a[(renamed_a['GPA_9th_grade'].notnull()) &\n",
      "          (renamed_a['daysabs_9th_grade'].notnull()) &\n",
      "          (renamed_a['transferred_out_before_graduating'] == 0)]['dropout_outcome'].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "0    0.91974\n",
        "1    0.08026\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Roughly 10.9% of 9th grade students in the class of 2012 drop out of\n",
      "# high school.\n",
      "renamed_a[(renamed_a['GPA_9th_grade'].notnull())&\n",
      "          (renamed_a['daysabs_9th_grade'].notnull())&\n",
      "          (renamed_a['transferred_out_before_graduating'] == 0)]['fail_to_finish_high_school_in_4_years'].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0    0.890998\n",
        "1    0.109002\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Roughly 6.5% of 9th grade students in the class of 2013 drop out of\n",
      "# high school.\n",
      "renamed_b[(renamed_b['GPA_9th_grade'].notnull())&\n",
      "          (renamed_b['daysabs_9th_grade'].notnull())&\n",
      "          (renamed_b['transferred_out_before_graduating'] == 0)]['dropout_outcome'].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0    0.934252\n",
        "1    0.065748\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Roughly 10.3% of 9th grade students in the class of 2013 drop out of\n",
      "# high school.\n",
      "renamed_b[(renamed_b['GPA_9th_grade'].notnull()) &\n",
      "          (renamed_b['daysabs_9th_grade'].notnull())&\n",
      "          (renamed_b['transferred_out_before_graduating'] == 0)]['fail_to_finish_high_school_in_4_years'].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "0    0.896607\n",
        "1    0.103393\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Modeling 2013 using 2012"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outcome_col = 'fail_to_finish_high_school_in_4_years'\n",
      "feature_cols = [\n",
      "#  'External_Student_ID',\n",
      "#  'earliest_reporting_year_majority_vote',\n",
      " 'retained_in_8_majority_vote',\n",
      "#  'retained_in_9_majority_vote',\n",
      "#  'retained_in_10_majority_vote',\n",
      "#  'retained_in_11_majority_vote',\n",
      "#  'expected_graduation_year_majority_vote',\n",
      "#  'dropout_outcome',\n",
      "#  'Grade_8th_grade',\n",
      " 'eds_8th_grade',\n",
      " 'swd_8th_grade',\n",
      "#  'Street_8th_grade',\n",
      " 'NumAdvanced_8th_grade',\n",
      " 'lep_8th_grade',\n",
      " 'reporting_year_8th_grade',\n",
      " 'GPA_Science_8th_grade',\n",
      " 'Num_Marks_8th_grade',\n",
      " 'NumAdvanced_SocSci_8th_grade',\n",
      " 'times_tardy_8th_grade',\n",
      " 'sex_8th_grade',\n",
      " 'Num_Science_8th_grade',\n",
      " 'GPA_SocSci_8th_grade',\n",
      " 'CITY_8th_grade',\n",
      "#  'grade_8th_grade',\n",
      " 'Num_SocSci_8th_grade',\n",
      " 'GPA_ENG_8th_grade',\n",
      " 'NumAdvanced_Science_8th_grade',\n",
      " 'GPA_8th_grade',\n",
      " 'NumAdvanced_ENG_8th_grade',\n",
      " 'exc_abs_8th_grade',\n",
      " 'daysabs_8th_grade',\n",
      " 'Num_ENG_8th_grade',\n",
      " 'ZIP_8th_grade',\n",
      " 'ethnic_8th_grade',\n",
      " 'Num_Math_8th_grade',\n",
      " 'unexc_abs_8th_grade',\n",
      " 'STATE_8th_grade',\n",
      " 'NumAdvanced_Math_8th_grade',\n",
      " 'GPA_Math_8th_grade',\n",
      " 'school_code_8th_grade',\n",
      "#  'GPA_Math_9th_grade',\n",
      "#  'CITY_9th_grade',\n",
      "#  'STATE_9th_grade',\n",
      "#  'GPA_SocSci_9th_grade',\n",
      "#  'sex_9th_grade',\n",
      "#  'daysabs_9th_grade',\n",
      "#  'lep_9th_grade',\n",
      "#  'Street_9th_grade',\n",
      "#  'Grade_9th_grade',\n",
      "#  'GPA_Science_9th_grade',\n",
      "#  'GPA_9th_grade',\n",
      "#  'NumAdvanced_SocSci_9th_grade',\n",
      "#  'reporting_year_9th_grade',\n",
      "#  'Num_Marks_9th_grade',\n",
      "#  'Num_Science_9th_grade',\n",
      "#  'grade_9th_grade',\n",
      "#  'Num_SocSci_9th_grade',\n",
      "#  'GPA_ENG_9th_grade',\n",
      "#  'times_tardy_9th_grade',\n",
      "#  'NumAdvanced_ENG_9th_grade',\n",
      "#  'Num_ENG_9th_grade',\n",
      "#  'eds_9th_grade',\n",
      "#  'unexc_abs_9th_grade',\n",
      "#  'ZIP_9th_grade',\n",
      "#  'NumAdvanced_Math_9th_grade',\n",
      "#  'Num_Math_9th_grade',\n",
      "#  'school_code_9th_grade',\n",
      "#  'ethnic_9th_grade',\n",
      "#  'exc_abs_9th_grade',\n",
      "#  'NumAdvanced_Science_9th_grade',\n",
      "#  'swd_9th_grade',\n",
      "#  'NumAdvanced_9th_grade',\n",
      "#  'GPA_Math_10th_grade',\n",
      "#  'CITY_10th_grade',\n",
      "#  'STATE_10th_grade',\n",
      "#  'GPA_SocSci_10th_grade',\n",
      "#  'sex_10th_grade',\n",
      "#  'daysabs_10th_grade',\n",
      "#  'lep_10th_grade',\n",
      "#  'Street_10th_grade',\n",
      "#  'Grade_10th_grade',\n",
      "#  'GPA_Science_10th_grade',\n",
      "#  'GPA_10th_grade',\n",
      "#  'NumAdvanced_SocSci_10th_grade',\n",
      "#  'reporting_year_10th_grade',\n",
      "#  'eds_10th_grade',\n",
      "#  'Num_Marks_10th_grade',\n",
      "#  'Num_Science_10th_grade',\n",
      "#  'grade_10th_grade',\n",
      "#  'Num_SocSci_10th_grade',\n",
      "#  'GPA_ENG_10th_grade',\n",
      "#  'NumAdvanced_Science_10th_grade',\n",
      "#  'times_tardy_10th_grade',\n",
      "#  'NumAdvanced_ENG_10th_grade',\n",
      "#  'Num_ENG_10th_grade',\n",
      "#  'unexc_abs_10th_grade',\n",
      "#  'ZIP_10th_grade',\n",
      "#  'NumAdvanced_Math_10th_grade',\n",
      "#  'Num_Math_10th_grade',\n",
      "#  'ethnic_10th_grade',\n",
      "#  'exc_abs_10th_grade',\n",
      "#  'school_code_10th_grade',\n",
      "#  'swd_10th_grade',\n",
      "#  'NumAdvanced_10th_grade',\n",
      "#  'STATE_11th_grade',\n",
      "#  'GPA_Math_11th_grade',\n",
      "#  'grade_11th_grade',\n",
      "#  'Grade_11th_grade',\n",
      "#  'Street_11th_grade',\n",
      "#  'sex_11th_grade',\n",
      "#  'lep_11th_grade',\n",
      "#  'GPA_Science_11th_grade',\n",
      "#  'GPA_11th_grade',\n",
      "#  'NumAdvanced_SocSci_11th_grade',\n",
      "#  'eds_11th_grade',\n",
      "#  'Num_Marks_11th_grade',\n",
      "#  'Num_Science_11th_grade',\n",
      "#  'GPA_SocSci_11th_grade',\n",
      "#  'reporting_year_11th_grade',\n",
      "#  'Num_SocSci_11th_grade',\n",
      "#  'GPA_ENG_11th_grade',\n",
      "#  'NumAdvanced_Science_11th_grade',\n",
      "#  'times_tardy_11th_grade',\n",
      "#  'NumAdvanced_ENG_11th_grade',\n",
      "#  'CITY_11th_grade',\n",
      "#  'Num_ENG_11th_grade',\n",
      "#  'daysabs_11th_grade',\n",
      "#  'unexc_abs_11th_grade',\n",
      "#  'ZIP_11th_grade',\n",
      "#  'NumAdvanced_Math_11th_grade',\n",
      "#  'Num_Math_11th_grade',\n",
      "#  'school_code_11th_grade',\n",
      "#  'ethnic_11th_grade',\n",
      "#  'exc_abs_11th_grade',\n",
      "#  'swd_11th_grade',\n",
      "#  'NumAdvanced_11th_grade',\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Abstracted from model/classification.py \n",
      "def preprocess(dataSet, dependentVar, doFeatureSelection=True, doPCA=False, nComponents=10):\n",
      "        \"\"\" Data pre-processing constructor.\n",
      "\n",
      "        Constructor to pre-process pandas DataFrames, extracting and encoding the outcome\n",
      "        labels (class), dropping them from the dataset and converting categorical variables\n",
      "        into integer numbers for compatibility with scikit-learn.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        dataSet : pd.DataFrame\n",
      "            The entire dataset as loaded and parsed in the main program\n",
      "        dependentVar : string\n",
      "            A string denoting the column to be used as the class\n",
      "        doFeatureSelection : bool\n",
      "            A flag to denote whether or not to perform feature selection\n",
      "        doPCA : bool\n",
      "            A flag to denote whether or not to perform principle component analysis\n",
      "        nComponents : int\n",
      "            The desired number of principle components\n",
      "\n",
      "        \"\"\"\n",
      "        # Encode nominal features to conform with sklearn\n",
      "        for i,tp in enumerate(dataSet.dtypes):\n",
      "            if tp == 'object':\n",
      "                unique_vals, dataSet.ix[:,i]  = np.unique(dataSet.ix[:,i] , return_inverse=True)\n",
      "\n",
      "        # Set the dependent variable (y) to the appropriate column\n",
      "        y = dataSet.loc[:,dependentVar]\n",
      "\n",
      "        # Transform that information to a format that scikit-learn understands\n",
      "        # This may be redundant at times\n",
      "        labels = preprocessing.LabelEncoder().fit_transform(y)\n",
      "\n",
      "        # Remove the dependent variable from training sets\n",
      "        X = dataSet.drop(dependentVar,1).values\n",
      "\n",
      "        # Perform entropy-based feature selection\n",
      "        if doFeatureSelection:\n",
      "            print 'Performing Feature Selection:'\n",
      "            print 'Shape of dataset before feature selection: ' + str(X.shape)\n",
      "            clf = DecisionTreeClassifier(criterion='entropy')\n",
      "            X = clf.fit(X, y).transform(X)\n",
      "            print 'Shape of dataset after feature selection: ' + str(X.shape) + '\\n'\n",
      "\n",
      "        # Normalize values\n",
      "        X = preprocessing.StandardScaler().fit(X).transform(X)\n",
      "\n",
      "        # Collapse features using principal component analysis\n",
      "        if doPCA:\n",
      "            print 'Performing PCA'\n",
      "            estimator = decomposition.PCA(n_components=nComponents)\n",
      "            X = estimator.fit_transform(X)\n",
      "            print 'Shape of dataset after PCA: ' + str(X.shape) + '\\n'\n",
      "\n",
      "        # Save processed dataset, labels and student ids\n",
      "        \n",
      "        return (X, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier(n_estimators=100, criterion='entropy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Making training data\n",
      "# Exclude students who transferred into Cabarrus after 8th grade\n",
      "# Also exclude students who transferred out and we therefore don't have \n",
      "# outcome labels for\n",
      "model_data = renamed_a[(renamed_a['daysabs_8th_grade'].notnull())\n",
      "                       & renamed_a['GPA_8th_grade'].notnull()\n",
      "                       & (renamed_a['transferred_out_before_graduating'] == 0)][feature_cols + [outcome_col]]\n",
      "y_labels = model_data[outcome_col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data[outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0    0.88446\n",
        "1    0.11554\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data.fillna(-1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = preprocess(model_data, outcome_col, doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_clf = clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Looking at in-sample precision\n",
      "scores = cross_val_score(clf, X, y, cv=10, scoring='precision', verbose=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.3s\n",
        "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.5s finished\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The idea is that this should be hopefully similar (or possibly slightly higher)\n",
      "# than the testing cohort\n",
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "0.65252572719677981"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Excluding students who have already dropped out by the grade we're using\n",
      "# data to predict up to.\n",
      "# Also exclude students who transferred into Cabarrus after the relevant grade\n",
      "# Also exclude students who will transfer out, as predictions on them are \n",
      "# moot given we cannot know their true outcome.\n",
      "\n",
      "# Note: There are no students who are recorded as having dropped out in 8th grade, \n",
      "exclude_grades = [8] \n",
      "testing_data = renamed_b[~renamed_b['Grade_dropout'].isin(exclude_grades)\n",
      "                              & (renamed_b['daysabs_8th_grade'].notnull())\n",
      "                              & renamed_b['GPA_8th_grade'].notnull()\n",
      "                              & (renamed_b['transferred_out_before_graduating'] == 0)]\n",
      "testing_data = testing_data[feature_cols + [outcome_col]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data[outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "0    0.890334\n",
        "1    0.109666\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data.fillna(-1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_X, testing_y = preprocess(testing_data, \n",
      "                                  outcome_col, \n",
      "                                  doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted_probs = fitted_clf.predict_proba(testing_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# getting probability of predicting dropout\n",
      "predicted_probs = [p[1] for p in predicted_probs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision, recall, thresholds = precision_recall_curve(testing_y, predicted_probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pr_auc = auc(recall, precision)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.plot(recall, precision, color = 'b', label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
      "pl.xlim([-0.05, 1.05])\n",
      "pl.ylim([-0.05, 1.05])\n",
      "pl.xlabel('Recall')\n",
      "pl.ylabel('Precision')\n",
      "pl.title('RF Precision-Recall')\n",
      "pl.legend(loc=\"best\")\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10b8a38d0>"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data['rf_predicted_probs'] = predicted_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data.sort(columns=['rf_predicted_probs'], \n",
      "              ascending=False, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Making a list to just look at the top and bottom ranked students\n",
      "examine_cols = ['GPA_8th_grade', \n",
      "                'daysabs_8th_grade',\n",
      "                'sex_8th_grade', \n",
      "                'ethnic_8th_grade', \n",
      "                'fail_to_finish_high_school_in_4_years',\n",
      "                'retained_in_8_majority_vote',]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data.head(20)[examine_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>GPA_8th_grade</th>\n",
        "      <th>daysabs_8th_grade</th>\n",
        "      <th>sex_8th_grade</th>\n",
        "      <th>ethnic_8th_grade</th>\n",
        "      <th>fail_to_finish_high_school_in_4_years</th>\n",
        "      <th>retained_in_8_majority_vote</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>691  </th>\n",
        "      <td> 68.83</td>\n",
        "      <td> 74</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5013 </th>\n",
        "      <td> 51.25</td>\n",
        "      <td> 56</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14412</th>\n",
        "      <td> 61.57</td>\n",
        "      <td> 32</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6871 </th>\n",
        "      <td> 73.14</td>\n",
        "      <td> 37</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14291</th>\n",
        "      <td> 63.33</td>\n",
        "      <td> 17</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8265 </th>\n",
        "      <td> 73.33</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>343  </th>\n",
        "      <td> 71.43</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9627 </th>\n",
        "      <td> 58.00</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6090 </th>\n",
        "      <td> 67.43</td>\n",
        "      <td> 39</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23701</th>\n",
        "      <td> 62.71</td>\n",
        "      <td> 54</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13909</th>\n",
        "      <td> 74.17</td>\n",
        "      <td> 21</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8992 </th>\n",
        "      <td> 62.00</td>\n",
        "      <td> 21</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9085 </th>\n",
        "      <td> 73.17</td>\n",
        "      <td> 17</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6429 </th>\n",
        "      <td> 75.00</td>\n",
        "      <td> 20</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9564 </th>\n",
        "      <td> 69.50</td>\n",
        "      <td> 86</td>\n",
        "      <td> 0</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5071 </th>\n",
        "      <td> 76.13</td>\n",
        "      <td> 51</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4334 </th>\n",
        "      <td> 73.38</td>\n",
        "      <td> 32</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9181 </th>\n",
        "      <td> 63.00</td>\n",
        "      <td> 19</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9757 </th>\n",
        "      <td> 65.63</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9712 </th>\n",
        "      <td> 62.63</td>\n",
        "      <td> 14</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "       GPA_8th_grade  daysabs_8th_grade  sex_8th_grade  ethnic_8th_grade  \\\n",
        "691            68.83                 74              0                 5   \n",
        "5013           51.25                 56              0                 5   \n",
        "14412          61.57                 32              1                 5   \n",
        "6871           73.14                 37              0                 5   \n",
        "14291          63.33                 17              0                 5   \n",
        "8265           73.33                 22              0                 5   \n",
        "343            71.43                 26              1                 5   \n",
        "9627           58.00                 26              0                 1   \n",
        "6090           67.43                 39              1                 1   \n",
        "23701          62.71                 54              1                 5   \n",
        "13909          74.17                 21              1                 5   \n",
        "8992           62.00                 21              1                 5   \n",
        "9085           73.17                 17              1                 5   \n",
        "6429           75.00                 20              1                 5   \n",
        "9564           69.50                 86              0                 4   \n",
        "5071           76.13                 51              0                 5   \n",
        "4334           73.38                 32              0                 2   \n",
        "9181           63.00                 19              1                 5   \n",
        "9757           65.63                 22              1                 2   \n",
        "9712           62.63                 14              1                 5   \n",
        "\n",
        "       fail_to_finish_high_school_in_4_years  retained_in_8_majority_vote  \n",
        "691                                        1                            0  \n",
        "5013                                       1                            0  \n",
        "14412                                      1                            0  \n",
        "6871                                       0                            0  \n",
        "14291                                      1                            1  \n",
        "8265                                       1                            0  \n",
        "343                                        1                            0  \n",
        "9627                                       1                            0  \n",
        "6090                                       1                            0  \n",
        "23701                                      1                            0  \n",
        "13909                                      0                            0  \n",
        "8992                                       1                            0  \n",
        "9085                                       0                            0  \n",
        "6429                                       1                            0  \n",
        "9564                                       1                            0  \n",
        "5071                                       1                            0  \n",
        "4334                                       0                            0  \n",
        "9181                                       1                            0  \n",
        "9757                                       1                            0  \n",
        "9712                                       1                            0  "
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data.tail(10)[examine_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>GPA_8th_grade</th>\n",
        "      <th>daysabs_8th_grade</th>\n",
        "      <th>sex_8th_grade</th>\n",
        "      <th>ethnic_8th_grade</th>\n",
        "      <th>fail_to_finish_high_school_in_4_years</th>\n",
        "      <th>retained_in_8_majority_vote</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>8310 </th>\n",
        "      <td> 89.17</td>\n",
        "      <td>  3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11378</th>\n",
        "      <td> 94.71</td>\n",
        "      <td>  3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8300 </th>\n",
        "      <td> 97.17</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8292 </th>\n",
        "      <td> 92.67</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8291 </th>\n",
        "      <td> 94.50</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8284 </th>\n",
        "      <td> 97.17</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8275 </th>\n",
        "      <td> 91.14</td>\n",
        "      <td>  5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8272 </th>\n",
        "      <td> 92.83</td>\n",
        "      <td> 12</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8268 </th>\n",
        "      <td> 89.00</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9606 </th>\n",
        "      <td> 91.00</td>\n",
        "      <td> 10</td>\n",
        "      <td> 0</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "       GPA_8th_grade  daysabs_8th_grade  sex_8th_grade  ethnic_8th_grade  \\\n",
        "8310           89.17                  3              0                 5   \n",
        "11378          94.71                  3              0                 5   \n",
        "8300           97.17                  6              0                 5   \n",
        "8292           92.67                  2              1                 5   \n",
        "8291           94.50                  2              1                 5   \n",
        "8284           97.17                  6              0                 5   \n",
        "8275           91.14                  5              1                 5   \n",
        "8272           92.83                 12              1                 5   \n",
        "8268           89.00                  6              1                 5   \n",
        "9606           91.00                 10              0                 4   \n",
        "\n",
        "       fail_to_finish_high_school_in_4_years  retained_in_8_majority_vote  \n",
        "8310                                       0                            0  \n",
        "11378                                      0                            0  \n",
        "8300                                       1                            0  \n",
        "8292                                       0                            0  \n",
        "8291                                       0                            0  \n",
        "8284                                       0                            0  \n",
        "8275                                       0                            0  \n",
        "8272                                       0                            0  \n",
        "8268                                       0                            0  \n",
        "9606                                       0                            0  "
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data[outcome_col][:num_students].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "1    0.766667\n",
        "0    0.233333\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data[outcome_col][:num_students].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "1    0.766667\n",
        "0    0.233333\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_data[testing_data['retained_in_8_majority_vote'] == 1][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "1    1\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_features, sorted_importances = diagnostics.get_feature_importances(fitted_clf, feature_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature Importances:\n",
        "----------\n",
        "1. GPA_8th_grade - 0.167\n",
        "2. GPA_ENG_8th_grade - 0.109\n",
        "3. GPA_SocSci_8th_grade - 0.097\n",
        "4. GPA_Science_8th_grade - 0.097\n",
        "5. GPA_Math_8th_grade - 0.093\n",
        "6. daysabs_8th_grade - 0.083\n",
        "7. unexc_abs_8th_grade - 0.081\n",
        "8. exc_abs_8th_grade - 0.059\n",
        "9. school_code_8th_grade - 0.037\n",
        "10. Num_Marks_8th_grade - 0.030\n",
        "11. ZIP_8th_grade - 0.029\n",
        "12. ethnic_8th_grade - 0.023\n",
        "13. CITY_8th_grade - 0.017\n",
        "14. eds_8th_grade - 0.016\n",
        "15. sex_8th_grade - 0.012\n",
        "16. swd_8th_grade - 0.012\n",
        "17. Num_Science_8th_grade - 0.010\n",
        "18. Num_ENG_8th_grade - 0.008\n",
        "19. retained_in_8_majority_vote - 0.007\n",
        "20. lep_8th_grade - 0.006\n",
        "21. Num_SocSci_8th_grade - 0.005\n",
        "22. NumAdvanced_Math_8th_grade - 0.002\n",
        "23. Num_Math_8th_grade - 0.001\n",
        "24. NumAdvanced_8th_grade - 0.001\n",
        "25. NumAdvanced_Science_8th_grade - 0.000\n",
        "26. times_tardy_8th_grade - 0.000\n",
        "27. NumAdvanced_SocSci_8th_grade - 0.000\n",
        "28. NumAdvanced_ENG_8th_grade - 0.000\n",
        "29. reporting_year_8th_grade - 0.000\n",
        "30. STATE_8th_grade - 0.000\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generating TSV for topmodel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'rf_predicted_probs' in testing_data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "export_data = testing_data[[outcome_col, 'rf_predicted_probs']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "export_data.rename(columns={outcome_col: 'actual',\n",
      "                            'rf_predicted_probs': 'pred_score'},\n",
      "                   inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "//anaconda/lib/python2.7/site-packages/pandas/core/frame.py:2417: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "  **kwargs)\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "export_data.to_csv?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Examining False Negatives\n",
      "These are students who predict as finishing on time who do not"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outcome_col"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "'fail_to_finish_high_school_in_4_years'"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Woah, this is kinda scary. There are a lot of students who do not finish\n",
      "# high school within 4 years but are not giving a probability above 0.5.\n",
      "testing_data[testing_data[outcome_col] == 1]['rf_predicted_probs'].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x1095b6c10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEBCAYAAACHTjUfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x104c05290>"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "examine_cols = [\n",
      " 'retained_in_8_majority_vote',\n",
      "#  'eds_8th_grade',\n",
      "#  'swd_8th_grade',\n",
      "#  'NumAdvanced_8th_grade',\n",
      "#  'lep_8th_grade',\n",
      "#  'reporting_year_8th_grade',\n",
      "#  'GPA_Science_8th_grade',\n",
      "#  'Num_Marks_8th_grade',\n",
      "#  'NumAdvanced_SocSci_8th_grade',\n",
      "#  'times_tardy_8th_grade',\n",
      "#  'sex_8th_grade',\n",
      "#  'Num_Science_8th_grade',\n",
      "#  'GPA_SocSci_8th_grade',\n",
      "#  'CITY_8th_grade',\n",
      "#  'Num_SocSci_8th_grade',\n",
      "#  'GPA_ENG_8th_grade',\n",
      "#  'NumAdvanced_Science_8th_grade',\n",
      " 'GPA_8th_grade',\n",
      "#  'NumAdvanced_ENG_8th_grade',\n",
      "#  'exc_abs_8th_grade',\n",
      " 'daysabs_8th_grade',\n",
      "#  'Num_ENG_8th_grade',\n",
      "#  'ZIP_8th_grade',\n",
      "#  'ethnic_8th_grade',\n",
      "#  'Num_Math_8th_grade',\n",
      "#  'unexc_abs_8th_grade',\n",
      "#  'STATE_8th_grade',\n",
      "#  'NumAdvanced_Math_8th_grade',\n",
      "#  'GPA_Math_8th_grade',\n",
      "#  'school_code_8th_grade'\n",
      " 'dropout_outcome',\n",
      " 'fail_to_finish_high_school_in_4_years', \n",
      " 'retained_in_9_majority_vote',\n",
      " 'retained_in_10_majority_vote',\n",
      " 'retained_in_11_majority_vote',\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b[(testing_cohort_b[outcome_col] == 1)].tail(20)[examine_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>retained_in_8_majority_vote</th>\n",
        "      <th>GPA_8th_grade</th>\n",
        "      <th>daysabs_8th_grade</th>\n",
        "      <th>dropout_outcome</th>\n",
        "      <th>fail_to_finish_high_school_in_4_years</th>\n",
        "      <th>retained_in_9_majority_vote</th>\n",
        "      <th>retained_in_10_majority_vote</th>\n",
        "      <th>retained_in_11_majority_vote</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>20334</th>\n",
        "      <td> 0</td>\n",
        "      <td> 94.14</td>\n",
        "      <td>  7</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8751 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 91.57</td>\n",
        "      <td> 10</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9478 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 88.43</td>\n",
        "      <td>  4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6600 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 85.71</td>\n",
        "      <td>  4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6615 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 88.71</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11551</th>\n",
        "      <td> 0</td>\n",
        "      <td> 92.50</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14499</th>\n",
        "      <td> 0</td>\n",
        "      <td> 81.67</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21362</th>\n",
        "      <td> 0</td>\n",
        "      <td> 96.50</td>\n",
        "      <td> 13</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22346</th>\n",
        "      <td> 0</td>\n",
        "      <td> 85.29</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20329</th>\n",
        "      <td> 0</td>\n",
        "      <td> 94.17</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9283 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 96.71</td>\n",
        "      <td> 14</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>195  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 95.50</td>\n",
        "      <td>  1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9191 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 88.50</td>\n",
        "      <td> 11</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22085</th>\n",
        "      <td> 0</td>\n",
        "      <td> 97.00</td>\n",
        "      <td>  8</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9391 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 86.50</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6376 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 91.14</td>\n",
        "      <td>  1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6265 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 93.00</td>\n",
        "      <td>  7</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8300 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 97.17</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14402</th>\n",
        "      <td> 0</td>\n",
        "      <td> 90.00</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6099 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 91.86</td>\n",
        "      <td>  6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "       retained_in_8_majority_vote  GPA_8th_grade  daysabs_8th_grade  \\\n",
        "20334                            0          94.14                  7   \n",
        "8751                             0          91.57                 10   \n",
        "9478                             0          88.43                  4   \n",
        "6600                             0          85.71                  4   \n",
        "6615                             0          88.71                  1   \n",
        "11551                            0          92.50                  6   \n",
        "14499                            0          81.67                  6   \n",
        "21362                            0          96.50                 13   \n",
        "22346                            0          85.29                  4   \n",
        "20329                            0          94.17                  6   \n",
        "9283                             0          96.71                 14   \n",
        "195                              0          95.50                  1   \n",
        "9191                             0          88.50                 11   \n",
        "22085                            0          97.00                  8   \n",
        "9391                             0          86.50                  2   \n",
        "6376                             0          91.14                  1   \n",
        "6265                             0          93.00                  7   \n",
        "8300                             0          97.17                  6   \n",
        "14402                            0          90.00                  6   \n",
        "6099                             0          91.86                  6   \n",
        "\n",
        "       dropout_outcome  fail_to_finish_high_school_in_4_years  \\\n",
        "20334                0                                      1   \n",
        "8751                 0                                      1   \n",
        "9478                 0                                      1   \n",
        "6600                 0                                      1   \n",
        "6615                 1                                      1   \n",
        "11551                0                                      1   \n",
        "14499                1                                      1   \n",
        "21362                0                                      1   \n",
        "22346                1                                      1   \n",
        "20329                0                                      1   \n",
        "9283                 0                                      1   \n",
        "195                  0                                      1   \n",
        "9191                 0                                      1   \n",
        "22085                0                                      1   \n",
        "9391                 1                                      1   \n",
        "6376                 0                                      1   \n",
        "6265                 0                                      1   \n",
        "8300                 0                                      1   \n",
        "14402                1                                      1   \n",
        "6099                 0                                      1   \n",
        "\n",
        "       retained_in_9_majority_vote  retained_in_10_majority_vote  \\\n",
        "20334                            0                             0   \n",
        "8751                             0                             0   \n",
        "9478                             0                             0   \n",
        "6600                             0                             0   \n",
        "6615                             0                             0   \n",
        "11551                            0                             0   \n",
        "14499                            0                             1   \n",
        "21362                            0                             0   \n",
        "22346                            0                             0   \n",
        "20329                            0                             0   \n",
        "9283                             0                             0   \n",
        "195                              0                             0   \n",
        "9191                             0                             0   \n",
        "22085                            0                             0   \n",
        "9391                             0                             0   \n",
        "6376                             0                             0   \n",
        "6265                             0                             0   \n",
        "8300                             0                             0   \n",
        "14402                            0                             0   \n",
        "6099                             0                             0   \n",
        "\n",
        "       retained_in_11_majority_vote  \n",
        "20334                             0  \n",
        "8751                              0  \n",
        "9478                              0  \n",
        "6600                              0  \n",
        "6615                              0  \n",
        "11551                             0  \n",
        "14499                             0  \n",
        "21362                             0  \n",
        "22346                             0  \n",
        "20329                             0  \n",
        "9283                              0  \n",
        "195                               0  \n",
        "9191                              0  \n",
        "22085                             0  \n",
        "9391                              0  \n",
        "6376                              0  \n",
        "6265                              0  \n",
        "8300                              0  \n",
        "14402                             0  \n",
        "6099                              0  "
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.api as sm\n",
      "import random\n",
      "from preprocessing import empirical_imputation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outcome_col = 'fail_to_finish_high_school_in_4_years'\n",
      "feature_cols = [\n",
      "#  'External_Student_ID',\n",
      "#  'earliest_reporting_year_majority_vote',\n",
      " 'retained_in_8_majority_vote',\n",
      "#  'retained_in_9_majority_vote',\n",
      "#  'retained_in_10_majority_vote',\n",
      "#  'retained_in_11_majority_vote',\n",
      "#  'expected_graduation_year_majority_vote',\n",
      "#  'fail_to_finish_high_school_in_4_years',\n",
      "#  'dropout_outcome',\n",
      "#  'Grade_8th_grade',\n",
      "#  'eds_8th_grade',\n",
      " 'swd_8th_grade',\n",
      "#  'Street_8th_grade',\n",
      " 'NumAdvanced_8th_grade',\n",
      " 'lep_8th_grade',\n",
      "#  'reporting_year_8th_grade',\n",
      " 'GPA_Science_8th_grade',\n",
      " 'Num_Marks_8th_grade',\n",
      "#  'NumAdvanced_SocSci_8th_grade',\n",
      "#  'times_tardy_8th_grade',\n",
      " 'sex_8th_grade',\n",
      " 'Num_Science_8th_grade',\n",
      " 'GPA_SocSci_8th_grade',\n",
      " 'CITY_8th_grade',\n",
      " 'grade_8th_grade',\n",
      " 'Num_SocSci_8th_grade',\n",
      " 'GPA_ENG_8th_grade',\n",
      " 'NumAdvanced_Science_8th_grade',\n",
      " 'GPA_8th_grade',\n",
      " 'NumAdvanced_ENG_8th_grade',\n",
      " 'exc_abs_8th_grade',\n",
      "#  'daysabs_8th_grade',\n",
      " 'Num_ENG_8th_grade',\n",
      " 'ZIP_8th_grade',\n",
      " 'ethnic_8th_grade',\n",
      " 'Num_Math_8th_grade',\n",
      " 'unexc_abs_8th_grade',\n",
      " 'STATE_8th_grade',\n",
      " 'NumAdvanced_Math_8th_grade',\n",
      " 'GPA_Math_8th_grade',\n",
      " 'school_code_8th_grade',\n",
      "#  'GPA_Math_9th_grade',\n",
      "#  'CITY_9th_grade',\n",
      "#  'STATE_9th_grade',\n",
      "#  'GPA_SocSci_9th_grade',\n",
      "#  'sex_9th_grade',\n",
      "#  'daysabs_9th_grade',\n",
      "#  'lep_9th_grade',\n",
      "#  'Street_9th_grade',\n",
      "#  'Grade_9th_grade',\n",
      "#  'GPA_Science_9th_grade',\n",
      "#  'GPA_9th_grade',\n",
      "#  'NumAdvanced_SocSci_9th_grade',\n",
      "#  'reporting_year_9th_grade',\n",
      "#  'Num_Marks_9th_grade',\n",
      "#  'Num_Science_9th_grade',\n",
      "#  'grade_9th_grade',\n",
      "#  'Num_SocSci_9th_grade',\n",
      "#  'GPA_ENG_9th_grade',\n",
      "#  'times_tardy_9th_grade',\n",
      "#  'NumAdvanced_ENG_9th_grade',\n",
      "#  'Num_ENG_9th_grade',\n",
      "#  'eds_9th_grade',\n",
      "#  'unexc_abs_9th_grade',\n",
      "#  'ZIP_9th_grade',\n",
      "#  'NumAdvanced_Math_9th_grade',\n",
      "#  'Num_Math_9th_grade',\n",
      "#  'school_code_9th_grade',\n",
      "#  'ethnic_9th_grade',\n",
      "#  'exc_abs_9th_grade',\n",
      "#  'NumAdvanced_Science_9th_grade',\n",
      "#  'swd_9th_grade',\n",
      "#  'NumAdvanced_9th_grade',\n",
      "#  'GPA_Math_10th_grade',\n",
      "#  'CITY_10th_grade',\n",
      "#  'STATE_10th_grade',\n",
      "#  'GPA_SocSci_10th_grade',\n",
      "#  'sex_10th_grade',\n",
      "#  'daysabs_10th_grade',\n",
      "#  'lep_10th_grade',\n",
      "#  'Street_10th_grade',\n",
      "#  'Grade_10th_grade',\n",
      "#  'GPA_Science_10th_grade',\n",
      "#  'GPA_10th_grade',\n",
      "#  'NumAdvanced_SocSci_10th_grade',\n",
      "#  'reporting_year_10th_grade',\n",
      "#  'eds_10th_grade',\n",
      "#  'Num_Marks_10th_grade',\n",
      "#  'Num_Science_10th_grade',\n",
      "#  'grade_10th_grade',\n",
      "#  'Num_SocSci_10th_grade',\n",
      "#  'GPA_ENG_10th_grade',\n",
      "#  'NumAdvanced_Science_10th_grade',\n",
      "#  'times_tardy_10th_grade',\n",
      "#  'NumAdvanced_ENG_10th_grade',\n",
      "#  'Num_ENG_10th_grade',\n",
      "#  'unexc_abs_10th_grade',\n",
      "#  'ZIP_10th_grade',\n",
      "#  'NumAdvanced_Math_10th_grade',\n",
      "#  'Num_Math_10th_grade',\n",
      "#  'ethnic_10th_grade',\n",
      "#  'exc_abs_10th_grade',\n",
      "#  'school_code_10th_grade',\n",
      "#  'swd_10th_grade',\n",
      "#  'NumAdvanced_10th_grade',\n",
      "#  'STATE_11th_grade',\n",
      "#  'GPA_Math_11th_grade',\n",
      "#  'grade_11th_grade',\n",
      "#  'Grade_11th_grade',\n",
      "#  'Street_11th_grade',\n",
      "#  'sex_11th_grade',\n",
      "#  'lep_11th_grade',\n",
      "#  'GPA_Science_11th_grade',\n",
      "#  'GPA_11th_grade',\n",
      "#  'NumAdvanced_SocSci_11th_grade',\n",
      "#  'eds_11th_grade',\n",
      "#  'Num_Marks_11th_grade',\n",
      "#  'Num_Science_11th_grade',\n",
      "#  'GPA_SocSci_11th_grade',\n",
      "#  'reporting_year_11th_grade',\n",
      "#  'Num_SocSci_11th_grade',\n",
      "#  'GPA_ENG_11th_grade',\n",
      "#  'NumAdvanced_Science_11th_grade',\n",
      "#  'times_tardy_11th_grade',\n",
      "#  'NumAdvanced_ENG_11th_grade',\n",
      "#  'CITY_11th_grade',\n",
      "#  'Num_ENG_11th_grade',\n",
      "#  'daysabs_11th_grade',\n",
      "#  'unexc_abs_11th_grade',\n",
      "#  'ZIP_11th_grade',\n",
      "#  'NumAdvanced_Math_11th_grade',\n",
      "#  'Num_Math_11th_grade',\n",
      "#  'school_code_11th_grade',\n",
      "#  'ethnic_11th_grade',\n",
      "#  'exc_abs_11th_grade',\n",
      "#  'swd_11th_grade',\n",
      "#  'NumAdvanced_11th_grade',\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So that this is replicable\n",
      "random.seed = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_training_data = pd.DataFrame()\n",
      "imputed_training_data[outcome_col] = model_data[outcome_col]\n",
      "imputed_training_data['intercept'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data = pd.DataFrame()\n",
      "imputed_testing_data[outcome_col] = testing_cohort_b[outcome_col]\n",
      "imputed_testing_data['intercept'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in feature_cols:\n",
      "    s = model_data[col].copy()\n",
      "    imputed_training_data[col] = empirical_imputation(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for col in feature_cols:\n",
      "    s = testing_cohort_b[col].copy()\n",
      "    imputed_testing_data[col] = empirical_imputation(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_nominal(dataframe):\n",
      "    for i, tp in enumerate(dataframe.dtypes):\n",
      "        if tp == 'object':\n",
      "            unique_vals, dataframe.ix[:,i] = np.unique(dataframe.ix[:,i] , return_inverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "convert_nominal(imputed_training_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.linalg.matrix_rank(imputed_training_data[feature_cols])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "23"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_training_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "(1740, 28)"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = sm.Logit(imputed_training_data[outcome_col], \n",
      "                       imputed_training_data[feature_cols + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_logit_model = logit_model.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LinAlgError",
       "evalue": "Singular matrix",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-80-18b51dbd5089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted_logit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBinaryResultsWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscretefit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[1;32m    163\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[0;31m# up to subclasses to wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                              \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                              hess=hess)\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# xopt should be None and retvals is argmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m_fit_mle_newton\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0moldparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         newparams = oldparams - np.dot(np.linalg.inv(H),\n\u001b[0m\u001b[1;32m    406\u001b[0m                 score(oldparams))\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretall\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_logit_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'fitted_logit_model' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-81-903dfd72a007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitted_logit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'fitted_logit_model' is not defined"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data['4 Feature Log Prob'] = fitted_logit_model.predict(imputed_testing_data[feature_cols + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 729
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data.sort('4 Feature Log Prob', inplace=True, ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 737
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students=100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 738
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data[testing_cohort_b['transferred_out_before_graduating'] == 0][:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 739,
       "text": [
        "1    0.62\n",
        "0    0.38\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 739
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the Bhanpuri-Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rule_based_outcome(row):\n",
      "    score = 0\n",
      "    retained = row['retained_in_8_majority_vote']\n",
      "    days_abs = row['daysabs_8th_grade']\n",
      "    gpa = row['GPA_8th_grade']\n",
      "    num_marks = row['Num_Marks_8th_grade']\n",
      "    if ~pd.isnull(gpa) and (gpa <= 72.7):\n",
      "        score += 1\n",
      "    if ~pd.isnull(num_marks) and (num_marks <= 4):\n",
      "        score += 1\n",
      "    if ~pd.isnull(days_abs) and (days_abs >= 23):\n",
      "        score += 1\n",
      "    if ~pd.isnull(retained) and (retained == 1):\n",
      "        score += 1\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 465
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b['Rule Predictions'] = testing_cohort_b.apply(rule_based_outcome,\n",
      "                                                              axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 466
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b.sort('Rule Predictions', inplace=True, ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 467
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 468
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b[testing_cohort_b['transferred_out_before_graduating'] == 0][:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 469,
       "text": [
        "1    0.58\n",
        "0    0.42\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 469
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simple Decision Tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_cols = ['retained_in_8_majority_vote',\n",
      "    'daysabs_8th_grade',\n",
      "    'GPA_8th_grade',\n",
      "    'Num_Marks_8th_grade',]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 370
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 371
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier(n_estimators=100, criterion='entropy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 372
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = clf.fit(model_data[feature_cols].fillna(-1), model_data[outcome_col])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 373
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preds = clf.predict(testing_cohort_b[feature_cols].fillna(-1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 374
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b['Random Forest Classification'] = preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b['Random Forest Classification'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 376,
       "text": [
        "0    1630\n",
        "1     139\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 377
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_cohort_b[(testing_cohort_b['Random Forest Classification'] == 1)\n",
      "                 & (testing_cohort_b['transferred_out_before_graduating'] == 0)][:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 378,
       "text": [
        "1    0.59\n",
        "0    0.41\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 378
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Doing Feature Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outcome_col = 'fail_to_finish_high_school_in_4_years'\n",
      "feature_cols = [\n",
      "#  'External_Student_ID',\n",
      "#  'earliest_reporting_year_majority_vote',\n",
      " 'retained_in_8_majority_vote',\n",
      "#  'retained_in_9_majority_vote',\n",
      "#  'retained_in_10_majority_vote',\n",
      "#  'retained_in_11_majority_vote',\n",
      "#  'expected_graduation_year_majority_vote',\n",
      "#  'fail_to_finish_high_school_in_4_years',\n",
      "#  'dropout_outcome',\n",
      " 'Grade_8th_grade',\n",
      " 'eds_8th_grade',\n",
      " 'swd_8th_grade',\n",
      "#  'Street_8th_grade',\n",
      " 'NumAdvanced_8th_grade',\n",
      " 'lep_8th_grade',\n",
      " 'reporting_year_8th_grade',\n",
      " 'GPA_Science_8th_grade',\n",
      " 'Num_Marks_8th_grade',\n",
      " 'NumAdvanced_SocSci_8th_grade',\n",
      " 'times_tardy_8th_grade',\n",
      " 'sex_8th_grade',\n",
      " 'Num_Science_8th_grade',\n",
      " 'GPA_SocSci_8th_grade',\n",
      " 'CITY_8th_grade',\n",
      " 'grade_8th_grade',\n",
      " 'Num_SocSci_8th_grade',\n",
      " 'GPA_ENG_8th_grade',\n",
      " 'NumAdvanced_Science_8th_grade',\n",
      " 'GPA_8th_grade',\n",
      " 'NumAdvanced_ENG_8th_grade',\n",
      " 'exc_abs_8th_grade',\n",
      " 'daysabs_8th_grade',\n",
      " 'Num_ENG_8th_grade',\n",
      " 'ZIP_8th_grade',\n",
      " 'ethnic_8th_grade',\n",
      " 'Num_Math_8th_grade',\n",
      " 'unexc_abs_8th_grade',\n",
      " 'STATE_8th_grade',\n",
      " 'NumAdvanced_Math_8th_grade',\n",
      " 'GPA_Math_8th_grade',\n",
      " 'school_code_8th_grade',\n",
      "#  'GPA_Math_9th_grade',\n",
      "#  'CITY_9th_grade',\n",
      "#  'STATE_9th_grade',\n",
      "#  'GPA_SocSci_9th_grade',\n",
      "#  'sex_9th_grade',\n",
      "#  'daysabs_9th_grade',\n",
      "#  'lep_9th_grade',\n",
      "#  'Street_9th_grade',\n",
      "#  'Grade_9th_grade',\n",
      "#  'GPA_Science_9th_grade',\n",
      "#  'GPA_9th_grade',\n",
      "#  'NumAdvanced_SocSci_9th_grade',\n",
      "#  'reporting_year_9th_grade',\n",
      "#  'Num_Marks_9th_grade',\n",
      "#  'Num_Science_9th_grade',\n",
      "#  'grade_9th_grade',\n",
      "#  'Num_SocSci_9th_grade',\n",
      "#  'GPA_ENG_9th_grade',\n",
      "#  'times_tardy_9th_grade',\n",
      "#  'NumAdvanced_ENG_9th_grade',\n",
      "#  'Num_ENG_9th_grade',\n",
      "#  'eds_9th_grade',\n",
      "#  'unexc_abs_9th_grade',\n",
      "#  'ZIP_9th_grade',\n",
      "#  'NumAdvanced_Math_9th_grade',\n",
      "#  'Num_Math_9th_grade',\n",
      "#  'school_code_9th_grade',\n",
      "#  'ethnic_9th_grade',\n",
      "#  'exc_abs_9th_grade',\n",
      "#  'NumAdvanced_Science_9th_grade',\n",
      "#  'swd_9th_grade',\n",
      "#  'NumAdvanced_9th_grade',\n",
      "#  'GPA_Math_10th_grade',\n",
      "#  'CITY_10th_grade',\n",
      "#  'STATE_10th_grade',\n",
      "#  'GPA_SocSci_10th_grade',\n",
      "#  'sex_10th_grade',\n",
      "#  'daysabs_10th_grade',\n",
      "#  'lep_10th_grade',\n",
      "#  'Street_10th_grade',\n",
      "#  'Grade_10th_grade',\n",
      "#  'GPA_Science_10th_grade',\n",
      "#  'GPA_10th_grade',\n",
      "#  'NumAdvanced_SocSci_10th_grade',\n",
      "#  'reporting_year_10th_grade',\n",
      "#  'eds_10th_grade',\n",
      "#  'Num_Marks_10th_grade',\n",
      "#  'Num_Science_10th_grade',\n",
      "#  'grade_10th_grade',\n",
      "#  'Num_SocSci_10th_grade',\n",
      "#  'GPA_ENG_10th_grade',\n",
      "#  'NumAdvanced_Science_10th_grade',\n",
      "#  'times_tardy_10th_grade',\n",
      "#  'NumAdvanced_ENG_10th_grade',\n",
      "#  'Num_ENG_10th_grade',\n",
      "#  'unexc_abs_10th_grade',\n",
      "#  'ZIP_10th_grade',\n",
      "#  'NumAdvanced_Math_10th_grade',\n",
      "#  'Num_Math_10th_grade',\n",
      "#  'ethnic_10th_grade',\n",
      "#  'exc_abs_10th_grade',\n",
      "#  'school_code_10th_grade',\n",
      "#  'swd_10th_grade',\n",
      "#  'NumAdvanced_10th_grade',\n",
      "#  'STATE_11th_grade',\n",
      "#  'GPA_Math_11th_grade',\n",
      "#  'grade_11th_grade',\n",
      "#  'Grade_11th_grade',\n",
      "#  'Street_11th_grade',\n",
      "#  'sex_11th_grade',\n",
      "#  'lep_11th_grade',\n",
      "#  'GPA_Science_11th_grade',\n",
      "#  'GPA_11th_grade',\n",
      "#  'NumAdvanced_SocSci_11th_grade',\n",
      "#  'eds_11th_grade',\n",
      "#  'Num_Marks_11th_grade',\n",
      "#  'Num_Science_11th_grade',\n",
      "#  'GPA_SocSci_11th_grade',\n",
      "#  'reporting_year_11th_grade',\n",
      "#  'Num_SocSci_11th_grade',\n",
      "#  'GPA_ENG_11th_grade',\n",
      "#  'NumAdvanced_Science_11th_grade',\n",
      "#  'times_tardy_11th_grade',\n",
      "#  'NumAdvanced_ENG_11th_grade',\n",
      "#  'CITY_11th_grade',\n",
      "#  'Num_ENG_11th_grade',\n",
      "#  'daysabs_11th_grade',\n",
      "#  'unexc_abs_11th_grade',\n",
      "#  'ZIP_11th_grade',\n",
      "#  'NumAdvanced_Math_11th_grade',\n",
      "#  'Num_Math_11th_grade',\n",
      "#  'school_code_11th_grade',\n",
      "#  'ethnic_11th_grade',\n",
      "#  'exc_abs_11th_grade',\n",
      "#  'swd_11th_grade',\n",
      "#  'NumAdvanced_11th_grade',\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using a Decision Tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entropy_dt = DecisionTreeClassifier(criterion='entropy', random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gini_dt = DecisionTreeClassifier(criterion='gini', random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = renamed_a[feature_cols + [outcome_col]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In our feature importance, we exclude students who transferred into 8th grade\n",
      "# and those who transferred out of Cabarrus (and we thus don't know their outcome)\n",
      "model_data = model_data[(renamed_a['GPA_8th_grade'].notnull())\n",
      "                        & (renamed_a['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "(1731, 33)"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data.fillna(-1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This normalizes the data, as well as converts nominal features to\n",
      "# something sklearn can handle.\n",
      "# It doesn't do any feature selection by itself, and I want to do feature\n",
      "# selection more carefully and I want to inspect the features.\n",
      "X, y = preprocess(model_data, outcome_col, doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_model = entropy_dt.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gini_fitted_model = gini_dt.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entropy_sorted_features, entropy_sorted_importances = get_feature_importances(fitted_model, feature_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature Importances:\n",
        "----------\n",
        "1. GPA_8th_grade - 0.383\n",
        "2. GPA_Science_8th_grade - 0.111\n",
        "3. daysabs_8th_grade - 0.076\n",
        "4. GPA_Math_8th_grade - 0.067\n",
        "5. exc_abs_8th_grade - 0.066\n",
        "6. GPA_SocSci_8th_grade - 0.059\n",
        "7. school_code_8th_grade - 0.058\n",
        "8. GPA_ENG_8th_grade - 0.051\n",
        "9. unexc_abs_8th_grade - 0.031\n",
        "10. ethnic_8th_grade - 0.018\n",
        "11. ZIP_8th_grade - 0.017\n",
        "12. sex_8th_grade - 0.015\n",
        "13. Num_Marks_8th_grade - 0.014\n",
        "14. Num_Science_8th_grade - 0.010\n",
        "15. retained_in_8_majority_vote - 0.008\n",
        "16. eds_8th_grade - 0.007\n",
        "17. swd_8th_grade - 0.003\n",
        "18. CITY_8th_grade - 0.003\n",
        "19. Num_ENG_8th_grade - 0.003\n",
        "20. Num_SocSci_8th_grade - 0.000\n",
        "21. reporting_year_8th_grade - 0.000\n",
        "22. Grade_8th_grade - 0.000\n",
        "23. NumAdvanced_8th_grade - 0.000\n",
        "24. lep_8th_grade - 0.000\n",
        "25. STATE_8th_grade - 0.000\n",
        "26. NumAdvanced_Math_8th_grade - 0.000\n",
        "27. NumAdvanced_Science_8th_grade - 0.000\n",
        "28. NumAdvanced_SocSci_8th_grade - 0.000\n",
        "29. times_tardy_8th_grade - 0.000\n",
        "30. Num_Math_8th_grade - 0.000\n",
        "31. NumAdvanced_ENG_8th_grade - 0.000\n",
        "32. grade_8th_grade - 0.000\n"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gini_sorted_features, gini_sorted_importances = get_feature_importances(gini_fitted_model, feature_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature Importances:\n",
        "----------\n",
        "1. GPA_8th_grade - 0.320\n",
        "2. GPA_Science_8th_grade - 0.095\n",
        "3. daysabs_8th_grade - 0.089\n",
        "4. exc_abs_8th_grade - 0.083\n",
        "5. GPA_ENG_8th_grade - 0.081\n",
        "6. unexc_abs_8th_grade - 0.059\n",
        "7. GPA_Math_8th_grade - 0.054\n",
        "8. GPA_SocSci_8th_grade - 0.042\n",
        "9. school_code_8th_grade - 0.042\n",
        "10. Num_Marks_8th_grade - 0.038\n",
        "11. ZIP_8th_grade - 0.022\n",
        "12. retained_in_8_majority_vote - 0.017\n",
        "13. Num_Science_8th_grade - 0.012\n",
        "14. sex_8th_grade - 0.011\n",
        "15. ethnic_8th_grade - 0.010\n",
        "16. swd_8th_grade - 0.009\n",
        "17. eds_8th_grade - 0.008\n",
        "18. lep_8th_grade - 0.005\n",
        "19. CITY_8th_grade - 0.002\n",
        "20. Num_ENG_8th_grade - 0.001\n",
        "21. NumAdvanced_ENG_8th_grade - 0.000\n",
        "22. reporting_year_8th_grade - 0.000\n",
        "23. Grade_8th_grade - 0.000\n",
        "24. NumAdvanced_8th_grade - 0.000\n",
        "25. NumAdvanced_SocSci_8th_grade - 0.000\n",
        "26. NumAdvanced_Math_8th_grade - 0.000\n",
        "27. STATE_8th_grade - 0.000\n",
        "28. NumAdvanced_Science_8th_grade - 0.000\n",
        "29. times_tardy_8th_grade - 0.000\n",
        "30. Num_Math_8th_grade - 0.000\n",
        "31. Num_SocSci_8th_grade - 0.000\n",
        "32. grade_8th_grade - 0.000\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature Importances (Entropy):\n",
      "----------\n",
      "1. GPA_8th_grade - 0.383\n",
      "2. GPA_Science_8th_grade - 0.111\n",
      "3. daysabs_8th_grade - 0.076\n",
      "4. GPA_Math_8th_grade - 0.067\n",
      "5. exc_abs_8th_grade - 0.066\n",
      "6. GPA_SocSci_8th_grade - 0.059\n",
      "7. school_code_8th_grade - 0.058\n",
      "8. GPA_ENG_8th_grade - 0.051\n",
      "9. unexc_abs_8th_grade - 0.031\n",
      "10. ethnic_8th_grade - 0.018\n",
      "11. ZIP_8th_grade - 0.017\n",
      "12. sex_8th_grade - 0.015\n",
      "13. Num_Marks_8th_grade - 0.014\n",
      "14. Num_Science_8th_grade - 0.010\n",
      "15. retained_in_8_majority_vote - 0.008\n",
      "16. eds_8th_grade - 0.007\n",
      "17. swd_8th_grade - 0.003\n",
      "18. CITY_8th_grade - 0.003\n",
      "19. Num_ENG_8th_grade - 0.003\n",
      "20. Num_SocSci_8th_grade - 0.000\n",
      "21. reporting_year_8th_grade - 0.000\n",
      "22. Grade_8th_grade - 0.000\n",
      "23. NumAdvanced_8th_grade - 0.000\n",
      "24. lep_8th_grade - 0.000\n",
      "25. STATE_8th_grade - 0.000\n",
      "26. NumAdvanced_Math_8th_grade - 0.000\n",
      "27. NumAdvanced_Science_8th_grade - 0.000\n",
      "28. NumAdvanced_SocSci_8th_grade - 0.000\n",
      "29. times_tardy_8th_grade - 0.000\n",
      "30. Num_Math_8th_grade - 0.000\n",
      "31. NumAdvanced_ENG_8th_grade - 0.000\n",
      "32. grade_8th_grade - 0.000"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature Importances (Gini):\n",
      "----------\n",
      "1. GPA_8th_grade - 0.320\n",
      "2. GPA_Science_8th_grade - 0.095\n",
      "3. daysabs_8th_grade - 0.089\n",
      "4. exc_abs_8th_grade - 0.083\n",
      "5. GPA_ENG_8th_grade - 0.081\n",
      "6. unexc_abs_8th_grade - 0.059\n",
      "7. GPA_Math_8th_grade - 0.054\n",
      "8. GPA_SocSci_8th_grade - 0.042\n",
      "9. school_code_8th_grade - 0.042\n",
      "10. Num_Marks_8th_grade - 0.038\n",
      "11. ZIP_8th_grade - 0.022\n",
      "12. retained_in_8_majority_vote - 0.017\n",
      "13. Num_Science_8th_grade - 0.012\n",
      "14. sex_8th_grade - 0.011\n",
      "15. ethnic_8th_grade - 0.010\n",
      "16. swd_8th_grade - 0.009\n",
      "17. eds_8th_grade - 0.008\n",
      "18. lep_8th_grade - 0.005\n",
      "19. CITY_8th_grade - 0.002\n",
      "20. Num_ENG_8th_grade - 0.001\n",
      "21. NumAdvanced_ENG_8th_grade - 0.000\n",
      "22. reporting_year_8th_grade - 0.000\n",
      "23. Grade_8th_grade - 0.000\n",
      "24. NumAdvanced_8th_grade - 0.000\n",
      "25. NumAdvanced_SocSci_8th_grade - 0.000\n",
      "26. NumAdvanced_Math_8th_grade - 0.000\n",
      "27. STATE_8th_grade - 0.000\n",
      "28. NumAdvanced_Science_8th_grade - 0.000\n",
      "29. times_tardy_8th_grade - 0.000\n",
      "30. Num_Math_8th_grade - 0.000\n",
      "31. Num_SocSci_8th_grade - 0.000\n",
      "32. grade_8th_grade - 0.000"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Take the intersection of the two different measurements at the top 10 features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_n = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = set(gini_sorted_features[:top_n]).intersection(entropy_sorted_features[:top_n])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pprint(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['GPA_8th_grade',\n",
        "     'GPA_ENG_8th_grade',\n",
        "     'GPA_Math_8th_grade',\n",
        "     'GPA_Science_8th_grade',\n",
        "     'GPA_SocSci_8th_grade',\n",
        "     'daysabs_8th_grade',\n",
        "     'exc_abs_8th_grade',\n",
        "     'school_code_8th_grade',\n",
        "     'unexc_abs_8th_grade'])\n"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_features = list(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Now, run a decision tree, random forest and logistic regression using\n",
      "# just these features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exclude_grades = [8, 9] \n",
      "exclude_student_ids = dropout_data[dropout_data['Grade'].isin(exclude_grades)]['External_Student_ID'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 697
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exclude students who were transferred into Cabarrus after the relevant grade\n",
      "# dropped out in that grade\n",
      "# or transferred out (and we thus don't have outcome labels for)\n",
      "model_data = renamed_a[renamed_a['GPA_8th_grade'].notnull()\n",
      "                             & ~(renamed_a['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_a['transferred_out_before_graduating'] == 0)][feature_cols + [outcome_col]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 698
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data[outcome_col].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 699,
       "text": [
        "0    1531\n",
        "1     143\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 699
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt_clf = tree.DecisionTreeClassifier(criterion='gini', random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 700
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = renamed_b[renamed_b['GPA_8th_grade'].notnull()\n",
      "                             & ~(renamed_b['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_b['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 701
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data[outcome_col].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 703,
       "text": [
        "0    1577\n",
        "1     155\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 703
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filled_test_data = test_data.fillna(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 704
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filled_test_data[outcome_col].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 705,
       "text": [
        "0    1577\n",
        "1     155\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 705
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = model_data.fillna(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 706
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = preprocess(model_data, outcome_col, doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_dt_clf = dt_clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_X, testing_y = preprocess(filled_test_data, outcome_col, doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_probs = fitted_dt_clf.predict_proba(testing_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_probs = [p[1] for p in pred_probs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision, recall, thresholds = precision_recall_curve(testing_y, pred_probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "apr_auc = auc(recall, precision)\n",
      "pl.plot(recall, precision, color = 'b', label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
      "pl.xlim([-0.05, 1.05])\n",
      "pl.ylim([-0.05, 1.05])\n",
      "pl.xlabel('Recall')\n",
      "pl.ylabel('Precision')\n",
      "pl.title('RF Precision-Recall')\n",
      "pl.legend(loc=\"best\")\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEKo3P8HmpLlV5a/hrsAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10afcda10>"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filled_test_data['DT Predictions'] = pred_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 194"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filled_test_data.sort('DT Predictions', ascending=False)[:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 322,
       "text": [
        "0    0.664948\n",
        "1    0.335052\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using a random forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pred(clf, clf_name, model_data, test_data, feature_cols, \n",
      "         outcome_col):\n",
      "    ## Filling NAs\n",
      "    filled_model_data = model_data.fillna(-1)[feature_cols + [outcome_col]]\n",
      "    filled_test_data = test_data.fillna(-1)[feature_cols + [outcome_col]]\n",
      "    \n",
      "    # Preprocessing\n",
      "    X, y = preprocess(filled_model_data, outcome_col, \n",
      "                      doFeatureSelection=False)\n",
      "    testing_X, testing_y = preprocess(filled_test_data, outcome_col, \n",
      "                                      doFeatureSelection=False)\n",
      "    # Fitting model\n",
      "    fitted_clf = clf.fit(X, y)\n",
      "    \n",
      "    # Making Predictions\n",
      "    pred_probs = fitted_clf.predict_proba(testing_X)\n",
      "    pred_probs = [p[1] for p in pred_probs]\n",
      "    \n",
      "    # Plotting Precision-Recall AUC\n",
      "    precision, recall, thresholds = precision_recall_curve(testing_y, pred_probs)\n",
      "    apr_auc = auc(recall, precision)\n",
      "    pl.plot(recall, precision, color = 'b', label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
      "    pl.xlim([-0.05, 1.05])\n",
      "    pl.ylim([-0.05, 1.05])\n",
      "    pl.xlabel('Recall')\n",
      "    pl.ylabel('Precision')\n",
      "    pl.title('{} Precision-Recall'.format(clf_name))\n",
      "    pl.legend(loc=\"best\")\n",
      "    pl.show()\n",
      "    \n",
      "    # Appending a column\n",
      "    filled_test_data['{} Predicted Probs'.format(clf_name)] = pred_probs\n",
      "    return filled_test_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier(n_estimators=100, criterion='gini',\n",
      "                             random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pred(clf, 'RF', model_data, test_data, feature_cols, \n",
      "          outcome_col)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEZCAYAAACaWyIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10b07a1d0>"
       ]
      }
     ],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 194"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.sort('RF Predicted Probs', ascending=False)[:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 362,
       "text": [
        "0    0.510309\n",
        "1    0.489691\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 362
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using a logistic regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data['intercept'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 381
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data['intercept'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 390
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_features = ['GPA_Science_8th_grade',\n",
      "                     'GPA_8th_grade',\n",
      "                     'GPA_SocSci_8th_grade',\n",
      "#                      'daysabs_8th_grade',\n",
      "                     'GPA_Math_8th_grade',\n",
      "                     'school_code_8th_grade',\n",
      "                     'exc_abs_8th_grade',\n",
      "                     'unexc_abs_8th_grade',\n",
      "                     'GPA_ENG_8th_grade']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 385
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocessing import empirical_imputation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 400
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Impute model data using empirical draws"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(seed=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 428
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_training_data = pd.DataFrame()\n",
      "imputed_testing_data = pd.DataFrame()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 429
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in important_features:\n",
      "    s = model_data[col].copy()\n",
      "    imputed_training_data[col] = empirical_imputation(s)\n",
      "\n",
      "for col in important_features:\n",
      "    s = test_data[col].copy()\n",
      "    imputed_testing_data[col] = empirical_imputation(s)\n",
      "    \n",
      "imputed_training_data['intercept'] = 1\n",
      "imputed_training_data[outcome_col] = model_data[outcome_col]\n",
      "imputed_testing_data['intercept'] = 1\n",
      "imputed_testing_data[outcome_col] = test_data[outcome_col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 430
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = sm.Logit(imputed_training_data[outcome_col], imputed_training_data[important_features + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 431
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = logit_model.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Maximum number of iterations has been exceeded.\n",
        "         Current function value: 0.238071\n",
        "         Iterations: 35\n"
       ]
      }
     ],
     "prompt_number": 432
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th> <td>fail_to_finish_high_school_in_4_years</td> <th>  No. Observations:  </th>  <td>  1731</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                         <td>Logit</td>                 <th>  Df Residuals:      </th>  <td>  1722</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>                         <td>MLE</td>                  <th>  Df Model:          </th>  <td>     8</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>                    <td>Wed, 12 Nov 2014</td>            <th>  Pseudo R-squ.:     </th>  <td>0.3349</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                        <td>14:35:29</td>                <th>  Log-Likelihood:    </th> <td> -412.10</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>                     <td>False</td>                 <th>  LL-Null:           </th> <td> -619.60</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                                <td> </td>                   <th>  LLR p-value:       </th> <td>1.156e-84</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_8th_grade</th> <td>    0.0208</td> <td>    0.016</td> <td>    1.271</td> <td> 0.204</td> <td>   -0.011     0.053</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_8th_grade</th>         <td>   -0.1487</td> <td>    0.025</td> <td>   -5.943</td> <td> 0.000</td> <td>   -0.198    -0.100</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_8th_grade</th>  <td>   -0.0092</td> <td>    0.004</td> <td>   -2.246</td> <td> 0.025</td> <td>   -0.017    -0.001</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_8th_grade</th>    <td>   -0.0015</td> <td>    0.008</td> <td>   -0.181</td> <td> 0.856</td> <td>   -0.018     0.015</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_8th_grade</th> <td>    0.0137</td> <td>    0.020</td> <td>    0.701</td> <td> 0.483</td> <td>   -0.025     0.052</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_8th_grade</th>     <td>    0.0510</td> <td>    0.014</td> <td>    3.534</td> <td> 0.000</td> <td>    0.023     0.079</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_8th_grade</th>   <td>    0.0932</td> <td>    0.020</td> <td>    4.777</td> <td> 0.000</td> <td>    0.055     0.131</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_8th_grade</th>     <td>   -0.0171</td> <td>    0.008</td> <td>   -2.123</td> <td> 0.034</td> <td>   -0.033    -0.001</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>intercept</th>             <td>-1773.3342</td> <td> 2543.826</td> <td>   -0.697</td> <td> 0.486</td> <td>-6759.142  3212.474</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 433,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                                     Logit Regression Results                                    \n",
        "=================================================================================================\n",
        "Dep. Variable:     fail_to_finish_high_school_in_4_years   No. Observations:                 1731\n",
        "Model:                                             Logit   Df Residuals:                     1722\n",
        "Method:                                              MLE   Df Model:                            8\n",
        "Date:                                   Wed, 12 Nov 2014   Pseudo R-squ.:                  0.3349\n",
        "Time:                                           14:35:29   Log-Likelihood:                -412.10\n",
        "converged:                                         False   LL-Null:                       -619.60\n",
        "                                                           LLR p-value:                 1.156e-84\n",
        "=========================================================================================\n",
        "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "-----------------------------------------------------------------------------------------\n",
        "GPA_Science_8th_grade     0.0208      0.016      1.271      0.204        -0.011     0.053\n",
        "GPA_8th_grade            -0.1487      0.025     -5.943      0.000        -0.198    -0.100\n",
        "GPA_SocSci_8th_grade     -0.0092      0.004     -2.246      0.025        -0.017    -0.001\n",
        "GPA_Math_8th_grade       -0.0015      0.008     -0.181      0.856        -0.018     0.015\n",
        "school_code_8th_grade     0.0137      0.020      0.701      0.483        -0.025     0.052\n",
        "exc_abs_8th_grade         0.0510      0.014      3.534      0.000         0.023     0.079\n",
        "unexc_abs_8th_grade       0.0932      0.020      4.777      0.000         0.055     0.131\n",
        "GPA_ENG_8th_grade        -0.0171      0.008     -2.123      0.034        -0.033    -0.001\n",
        "intercept             -1773.3342   2543.826     -0.697      0.486     -6759.142  3212.474\n",
        "=========================================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 433
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_preds = logit_model.predict(imputed_testing_data[important_features + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 434
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data['Log Preds'] = log_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 435
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 194"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data.sort('Log Preds', ascending=False)[:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 449,
       "text": [
        "0    0.56701\n",
        "1    0.43299\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 449
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Adding the four rules"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 451
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = renamed_a[renamed_a['GPA_8th_grade'].notnull()\n",
      "                             & ~(renamed_a['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_a['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 936
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = renamed_b[renamed_b['GPA_8th_grade'].notnull()\n",
      "                             & ~(renamed_b['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_b['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 937
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_training_data['gpa_rule'] = imputed_training_data['GPA_8th_grade'].apply(lambda gpa: 1 if gpa <= 72.7 else 0)\n",
      "imputed_training_data['days_abs_rule'] = model_data['daysabs_8th_grade'].apply(lambda days_abs: 1 if days_abs >= 23 else 0)\n",
      "imputed_training_data['retained_rule'] = model_data['retained_in_8_majority_vote']\n",
      "imputed_training_data['num_marks_rule'] = model_data['Num_Marks_8th_grade'].apply(lambda marks: 1 if marks <= 4 else 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 938
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data['gpa_rule'] = imputed_testing_data['GPA_8th_grade'].apply(lambda gpa: 1 if gpa <= 72.7 else 0)\n",
      "imputed_testing_data['days_abs_rule'] = test_data['daysabs_8th_grade'].apply(lambda days_abs: 1 if days_abs >= 23 else 0)\n",
      "imputed_testing_data['retained_rule'] = test_data['retained_in_8_majority_vote']\n",
      "imputed_testing_data['num_marks_rule'] = test_data['Num_Marks_8th_grade'].apply(lambda marks: 1 if marks <= 4 else 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 939
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_features = ['GPA_Science_8th_grade',\n",
      "                     'GPA_8th_grade',\n",
      "                     'GPA_SocSci_8th_grade',\n",
      "                     'GPA_Math_8th_grade',\n",
      "                     'school_code_8th_grade',\n",
      "                     'exc_abs_8th_grade',\n",
      "                     'unexc_abs_8th_grade',\n",
      "                     'GPA_ENG_8th_grade',\n",
      "                     'gpa_rule',\n",
      "                     'days_abs_rule',\n",
      "                     'retained_rule',\n",
      "                     'num_marks_rule',\n",
      "                    ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 940
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = sm.Logit(imputed_training_data[outcome_col], imputed_training_data[important_features + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 941
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = logit_model.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Maximum number of iterations has been exceeded.\n",
        "         Current function value: 0.228205\n",
        "         Iterations: 35\n"
       ]
      }
     ],
     "prompt_number": 942
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th> <td>fail_to_finish_high_school_in_4_years</td> <th>  No. Observations:  </th>  <td>  1731</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                         <td>Logit</td>                 <th>  Df Residuals:      </th>  <td>  1718</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>                         <td>MLE</td>                  <th>  Df Model:          </th>  <td>    12</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>                    <td>Wed, 12 Nov 2014</td>            <th>  Pseudo R-squ.:     </th>  <td>0.3625</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                        <td>18:34:38</td>                <th>  Log-Likelihood:    </th> <td> -395.02</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>                     <td>False</td>                 <th>  LL-Null:           </th> <td> -619.60</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                                <td> </td>                   <th>  LLR p-value:       </th> <td>1.426e-88</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_8th_grade</th> <td>    0.0046</td> <td>    0.018</td> <td>    0.253</td> <td> 0.800</td> <td>   -0.031     0.041</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_8th_grade</th>         <td>   -0.1727</td> <td>    0.041</td> <td>   -4.224</td> <td> 0.000</td> <td>   -0.253    -0.093</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_8th_grade</th>  <td>    0.0392</td> <td>    0.014</td> <td>    2.723</td> <td> 0.006</td> <td>    0.011     0.067</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_8th_grade</th>    <td>   -0.0208</td> <td>    0.014</td> <td>   -1.527</td> <td> 0.127</td> <td>   -0.047     0.006</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_8th_grade</th> <td>    0.0217</td> <td>    0.021</td> <td>    1.048</td> <td> 0.295</td> <td>   -0.019     0.062</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_8th_grade</th>     <td>    0.0707</td> <td>    0.020</td> <td>    3.584</td> <td> 0.000</td> <td>    0.032     0.109</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_8th_grade</th>   <td>    0.1221</td> <td>    0.023</td> <td>    5.309</td> <td> 0.000</td> <td>    0.077     0.167</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_8th_grade</th>     <td>   -0.0058</td> <td>    0.015</td> <td>   -0.382</td> <td> 0.703</td> <td>   -0.036     0.024</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>gpa_rule</th>              <td>   -0.1161</td> <td>    0.313</td> <td>   -0.371</td> <td> 0.711</td> <td>   -0.730     0.498</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>days_abs_rule</th>         <td>   -0.7182</td> <td>    0.466</td> <td>   -1.543</td> <td> 0.123</td> <td>   -1.631     0.194</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>retained_rule</th>         <td>   39.4867</td> <td> 1.94e+07</td> <td> 2.04e-06</td> <td> 1.000</td> <td> -3.8e+07   3.8e+07</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>num_marks_rule</th>        <td>    2.5985</td> <td>    0.690</td> <td>    3.764</td> <td> 0.000</td> <td>    1.245     3.952</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>intercept</th>             <td>-2821.9171</td> <td> 2702.548</td> <td>   -1.044</td> <td> 0.296</td> <td>-8118.813  2474.979</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 943,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                                     Logit Regression Results                                    \n",
        "=================================================================================================\n",
        "Dep. Variable:     fail_to_finish_high_school_in_4_years   No. Observations:                 1731\n",
        "Model:                                             Logit   Df Residuals:                     1718\n",
        "Method:                                              MLE   Df Model:                           12\n",
        "Date:                                   Wed, 12 Nov 2014   Pseudo R-squ.:                  0.3625\n",
        "Time:                                           18:34:38   Log-Likelihood:                -395.02\n",
        "converged:                                         False   LL-Null:                       -619.60\n",
        "                                                           LLR p-value:                 1.426e-88\n",
        "=========================================================================================\n",
        "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "-----------------------------------------------------------------------------------------\n",
        "GPA_Science_8th_grade     0.0046      0.018      0.253      0.800        -0.031     0.041\n",
        "GPA_8th_grade            -0.1727      0.041     -4.224      0.000        -0.253    -0.093\n",
        "GPA_SocSci_8th_grade      0.0392      0.014      2.723      0.006         0.011     0.067\n",
        "GPA_Math_8th_grade       -0.0208      0.014     -1.527      0.127        -0.047     0.006\n",
        "school_code_8th_grade     0.0217      0.021      1.048      0.295        -0.019     0.062\n",
        "exc_abs_8th_grade         0.0707      0.020      3.584      0.000         0.032     0.109\n",
        "unexc_abs_8th_grade       0.1221      0.023      5.309      0.000         0.077     0.167\n",
        "GPA_ENG_8th_grade        -0.0058      0.015     -0.382      0.703        -0.036     0.024\n",
        "gpa_rule                 -0.1161      0.313     -0.371      0.711        -0.730     0.498\n",
        "days_abs_rule            -0.7182      0.466     -1.543      0.123        -1.631     0.194\n",
        "retained_rule            39.4867   1.94e+07   2.04e-06      1.000      -3.8e+07   3.8e+07\n",
        "num_marks_rule            2.5985      0.690      3.764      0.000         1.245     3.952\n",
        "intercept             -2821.9171   2702.548     -1.044      0.296     -8118.813  2474.979\n",
        "=========================================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 943
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_preds = logit_model.predict(imputed_testing_data[important_features + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 944
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data['Log + Rule Preds'] = log_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 945
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data['Log + Rule Preds'].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 946,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x11c192fd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEBCAYAAACe6Rn8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWqvEAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11c189f50>"
       ]
      }
     ],
     "prompt_number": 946
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 195"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 956
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data.sort('Log + Rule Preds', ascending=False)[:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 957,
       "text": [
        "0    0.533333\n",
        "1    0.466667\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 957
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Predictions on other years\n",
      "\n",
      "After some discussion, we decided to use a logistic regression model with the top 7 features + features associated with the 4 rules.\n",
      "\n",
      "That amounted to the basic below (where the grade can be replaced with the relevant grade, and previous grades are also appended):\n",
      "\n",
      "- GPA_Science_8th_grade\n",
      "- GPA_8th_grade\n",
      "- GPA_SocSci_8th_grade\n",
      "- GPA_Math_8th_grade\n",
      "- school_code_8th_grade\n",
      "- exc_abs_8th_grade\n",
      "- unexc_abs_8th_grade\n",
      "- GPA_ENG_8th_grade\n",
      "- retained_in_8\n",
      "- Num_Marks_8th_grade"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_grade = 11\n",
      "exclude_grades = range(8, last_grade+1)\n",
      "exclude_student_ids = dropout_data[dropout_data['Grade'].isin(exclude_grades)]['External_Student_ID'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "important_features = ['GPA_Science_{}th_grade'.format(last_grade),\n",
      "                     'GPA_{}th_grade'.format(last_grade),\n",
      "                     'GPA_SocSci_{}th_grade'.format(last_grade),\n",
      "                     'GPA_Math_{}th_grade'.format(last_grade),\n",
      "                     'school_code_{}th_grade'.format(last_grade),\n",
      "                     'exc_abs_{}th_grade'.format(last_grade),\n",
      "                     'unexc_abs_{}th_grade'.format(last_grade),\n",
      "                     'GPA_ENG_{}th_grade'.format(last_grade),\n",
      "                     'retained_in_{}_majority_vote'.format(last_grade),\n",
      "                     'Num_Marks_{}th_grade'.format(last_grade),\n",
      "                     ]\n",
      "                     \n",
      "for grade in range(8, last_grade):\n",
      "    previous_year_features = ['GPA_Science_{}th_grade'.format(grade),\n",
      "                     'GPA_{}th_grade'.format(grade),\n",
      "                     'GPA_SocSci_{}th_grade'.format(grade),\n",
      "                     'GPA_Math_{}th_grade'.format(grade),\n",
      "                     'school_code_{}th_grade'.format(grade),\n",
      "                     'exc_abs_{}th_grade'.format(grade),\n",
      "                     'unexc_abs_{}th_grade'.format(grade),\n",
      "                     'GPA_ENG_{}th_grade'.format(grade),\n",
      "                     'retained_in_{}_majority_vote'.format(grade),\n",
      "                     'Num_Marks_{}th_grade'.format(grade),\n",
      "                     ]\n",
      "    important_features += previous_year_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1273,
       "text": [
        "['GPA_Science_11th_grade',\n",
        " 'GPA_11th_grade',\n",
        " 'GPA_SocSci_11th_grade',\n",
        " 'GPA_Math_11th_grade',\n",
        " 'school_code_11th_grade',\n",
        " 'exc_abs_11th_grade',\n",
        " 'unexc_abs_11th_grade',\n",
        " 'GPA_ENG_11th_grade',\n",
        " 'retained_in_11_majority_vote',\n",
        " 'Num_Marks_11th_grade',\n",
        " 'GPA_Science_8th_grade',\n",
        " 'GPA_8th_grade',\n",
        " 'GPA_SocSci_8th_grade',\n",
        " 'GPA_Math_8th_grade',\n",
        " 'school_code_8th_grade',\n",
        " 'exc_abs_8th_grade',\n",
        " 'unexc_abs_8th_grade',\n",
        " 'GPA_ENG_8th_grade',\n",
        " 'retained_in_8_majority_vote',\n",
        " 'Num_Marks_8th_grade',\n",
        " 'GPA_Science_9th_grade',\n",
        " 'GPA_9th_grade',\n",
        " 'GPA_SocSci_9th_grade',\n",
        " 'GPA_Math_9th_grade',\n",
        " 'school_code_9th_grade',\n",
        " 'exc_abs_9th_grade',\n",
        " 'unexc_abs_9th_grade',\n",
        " 'GPA_ENG_9th_grade',\n",
        " 'retained_in_9_majority_vote',\n",
        " 'Num_Marks_9th_grade',\n",
        " 'GPA_Science_10th_grade',\n",
        " 'GPA_10th_grade',\n",
        " 'GPA_SocSci_10th_grade',\n",
        " 'GPA_Math_10th_grade',\n",
        " 'school_code_10th_grade',\n",
        " 'exc_abs_10th_grade',\n",
        " 'unexc_abs_10th_grade',\n",
        " 'GPA_ENG_10th_grade',\n",
        " 'retained_in_10_majority_vote',\n",
        " 'Num_Marks_10th_grade']"
       ]
      }
     ],
     "prompt_number": 1273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "renamed_a.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1274,
       "text": [
        "(2866, 161)"
       ]
      }
     ],
     "prompt_number": 1274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = renamed_a[renamed_a['GPA_{}th_grade'.format(last_grade)].notnull()\n",
      "                             & ~(renamed_a['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_a['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = renamed_b[renamed_b['GPA_{}th_grade'.format(last_grade)].notnull()\n",
      "                             & ~(renamed_b['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_b['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data[outcome_col].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1277,
       "text": [
        "0    1805\n",
        "1      88\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 1277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data[outcome_col].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1278,
       "text": [
        "0    1832\n",
        "1      93\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 1278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_training_data = pd.DataFrame()\n",
      "imputed_testing_data = pd.DataFrame()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in important_features:\n",
      "    s = model_data[col].copy()\n",
      "    imputed_training_data[col] = empirical_imputation(s)\n",
      "\n",
      "for col in important_features:\n",
      "    s = test_data[col].copy()\n",
      "    imputed_testing_data[col] = empirical_imputation(s)\n",
      "    \n",
      "imputed_training_data['intercept'] = 1\n",
      "imputed_training_data[outcome_col] = model_data[outcome_col]\n",
      "imputed_testing_data['intercept'] = 1\n",
      "imputed_testing_data[outcome_col] = test_data[outcome_col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1280
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model = sm.Logit(imputed_training_data[outcome_col], imputed_training_data[important_features + ['intercept']]).fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Maximum number of iterations has been exceeded.\n",
        "         Current function value: 0.116745\n",
        "         Iterations: 35\n"
       ]
      }
     ],
     "prompt_number": 1281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th> <td>fail_to_finish_high_school_in_4_years</td> <th>  No. Observations:  </th>  <td>  1893</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                         <td>Logit</td>                 <th>  Df Residuals:      </th>  <td>  1852</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>                         <td>MLE</td>                  <th>  Df Model:          </th>  <td>    40</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>                    <td>Wed, 12 Nov 2014</td>            <th>  Pseudo R-squ.:     </th>  <td>0.3791</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                        <td>19:14:18</td>                <th>  Log-Likelihood:    </th> <td> -221.00</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>                     <td>False</td>                 <th>  LL-Null:           </th> <td> -355.96</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                                <td> </td>                   <th>  LLR p-value:       </th> <td>6.950e-36</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_11th_grade</th>       <td>   -0.0053</td> <td>    0.016</td> <td>   -0.338</td> <td> 0.735</td> <td>   -0.036     0.025</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_11th_grade</th>               <td>    0.0113</td> <td>    0.041</td> <td>    0.276</td> <td> 0.782</td> <td>   -0.069     0.091</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_11th_grade</th>        <td>   -0.0033</td> <td>    0.014</td> <td>   -0.238</td> <td> 0.812</td> <td>   -0.030     0.024</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_11th_grade</th>          <td>    0.0017</td> <td>    0.013</td> <td>    0.126</td> <td> 0.900</td> <td>   -0.024     0.028</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_11th_grade</th>       <td> 1.412e-05</td> <td> 6.97e-06</td> <td>    2.027</td> <td> 0.043</td> <td> 4.65e-07  2.78e-05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_11th_grade</th>           <td>    0.1397</td> <td>    0.062</td> <td>    2.270</td> <td> 0.023</td> <td>    0.019     0.260</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_11th_grade</th>         <td>    0.0655</td> <td>    0.018</td> <td>    3.550</td> <td> 0.000</td> <td>    0.029     0.102</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_11th_grade</th>           <td>   -0.0337</td> <td>    0.015</td> <td>   -2.194</td> <td> 0.028</td> <td>   -0.064    -0.004</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>retained_in_11_majority_vote</th> <td>    0.8771</td> <td>    0.889</td> <td>    0.987</td> <td> 0.324</td> <td>   -0.865     2.619</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Num_Marks_11th_grade</th>         <td>    0.5091</td> <td>    0.089</td> <td>    5.714</td> <td> 0.000</td> <td>    0.334     0.684</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_8th_grade</th>        <td>    0.0061</td> <td>    0.020</td> <td>    0.303</td> <td> 0.762</td> <td>   -0.033     0.045</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_8th_grade</th>                <td>   -0.0223</td> <td>    0.032</td> <td>   -0.696</td> <td> 0.487</td> <td>   -0.085     0.041</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_8th_grade</th>         <td>   -0.0190</td> <td>    0.018</td> <td>   -1.065</td> <td> 0.287</td> <td>   -0.054     0.016</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_8th_grade</th>           <td>    0.0127</td> <td>    0.019</td> <td>    0.672</td> <td> 0.502</td> <td>   -0.024     0.050</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_8th_grade</th>        <td>    0.0637</td> <td>    0.028</td> <td>    2.254</td> <td> 0.024</td> <td>    0.008     0.119</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_8th_grade</th>            <td>    0.0102</td> <td>    0.034</td> <td>    0.301</td> <td> 0.763</td> <td>   -0.056     0.077</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_8th_grade</th>          <td>    0.0141</td> <td>    0.039</td> <td>    0.358</td> <td> 0.721</td> <td>   -0.063     0.091</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_8th_grade</th>            <td>   -0.0221</td> <td>    0.020</td> <td>   -1.093</td> <td> 0.275</td> <td>   -0.062     0.018</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>retained_in_8_majority_vote</th>  <td>   40.0174</td> <td> 2.24e+07</td> <td> 1.79e-06</td> <td> 1.000</td> <td>-4.38e+07  4.38e+07</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Num_Marks_8th_grade</th>          <td>   -0.4021</td> <td>    0.222</td> <td>   -1.813</td> <td> 0.070</td> <td>   -0.837     0.033</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_9th_grade</th>        <td>    0.0128</td> <td>    0.012</td> <td>    1.086</td> <td> 0.277</td> <td>   -0.010     0.036</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_9th_grade</th>                <td>   -0.0384</td> <td>    0.022</td> <td>   -1.716</td> <td> 0.086</td> <td>   -0.082     0.005</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_9th_grade</th>         <td>    0.0111</td> <td>    0.012</td> <td>    0.919</td> <td> 0.358</td> <td>   -0.013     0.035</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_9th_grade</th>           <td>   -0.0050</td> <td>    0.014</td> <td>   -0.365</td> <td> 0.715</td> <td>   -0.032     0.022</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_9th_grade</th>        <td> 3.996e-06</td> <td> 9.99e-06</td> <td>    0.400</td> <td> 0.689</td> <td>-1.56e-05  2.36e-05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_9th_grade</th>            <td>   -0.1461</td> <td>    0.061</td> <td>   -2.409</td> <td> 0.016</td> <td>   -0.265    -0.027</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_9th_grade</th>          <td>   -0.0358</td> <td>    0.027</td> <td>   -1.317</td> <td> 0.188</td> <td>   -0.089     0.017</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_9th_grade</th>            <td>    0.0183</td> <td>    0.011</td> <td>    1.652</td> <td> 0.098</td> <td>   -0.003     0.040</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>retained_in_9_majority_vote</th>  <td>    1.4089</td> <td>    0.430</td> <td>    3.279</td> <td> 0.001</td> <td>    0.567     2.251</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Num_Marks_9th_grade</th>          <td>   -0.2232</td> <td>    0.115</td> <td>   -1.939</td> <td> 0.052</td> <td>   -0.449     0.002</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Science_10th_grade</th>       <td>   -0.0088</td> <td>    0.013</td> <td>   -0.696</td> <td> 0.486</td> <td>   -0.034     0.016</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_10th_grade</th>               <td>   -0.0423</td> <td>    0.030</td> <td>   -1.405</td> <td> 0.160</td> <td>   -0.101     0.017</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_SocSci_10th_grade</th>        <td>    0.0160</td> <td>    0.015</td> <td>    1.057</td> <td> 0.291</td> <td>   -0.014     0.046</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_Math_10th_grade</th>          <td>    0.0069</td> <td>    0.012</td> <td>    0.559</td> <td> 0.576</td> <td>   -0.017     0.031</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>school_code_10th_grade</th>       <td>-1.619e-06</td> <td>  6.8e-06</td> <td>   -0.238</td> <td> 0.812</td> <td>-1.49e-05  1.17e-05</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>exc_abs_10th_grade</th>           <td>    0.0581</td> <td>    0.057</td> <td>    1.025</td> <td> 0.306</td> <td>   -0.053     0.169</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>unexc_abs_10th_grade</th>         <td>    0.0098</td> <td>    0.024</td> <td>    0.407</td> <td> 0.684</td> <td>   -0.037     0.057</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>GPA_ENG_10th_grade</th>           <td>    0.0258</td> <td>    0.013</td> <td>    1.955</td> <td> 0.051</td> <td>-6.58e-05     0.052</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>retained_in_10_majority_vote</th> <td>    0.2115</td> <td>    0.589</td> <td>    0.359</td> <td> 0.720</td> <td>   -0.944     1.367</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Num_Marks_10th_grade</th>         <td>    0.1207</td> <td>    0.161</td> <td>    0.749</td> <td> 0.454</td> <td>   -0.195     0.436</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>intercept</th>                    <td>-8297.5977</td> <td> 3679.568</td> <td>   -2.255</td> <td> 0.024</td> <td>-1.55e+04 -1085.777</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1282,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                                     Logit Regression Results                                    \n",
        "=================================================================================================\n",
        "Dep. Variable:     fail_to_finish_high_school_in_4_years   No. Observations:                 1893\n",
        "Model:                                             Logit   Df Residuals:                     1852\n",
        "Method:                                              MLE   Df Model:                           40\n",
        "Date:                                   Wed, 12 Nov 2014   Pseudo R-squ.:                  0.3791\n",
        "Time:                                           19:14:18   Log-Likelihood:                -221.00\n",
        "converged:                                         False   LL-Null:                       -355.96\n",
        "                                                           LLR p-value:                 6.950e-36\n",
        "================================================================================================\n",
        "                                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------------------------\n",
        "GPA_Science_11th_grade          -0.0053      0.016     -0.338      0.735        -0.036     0.025\n",
        "GPA_11th_grade                   0.0113      0.041      0.276      0.782        -0.069     0.091\n",
        "GPA_SocSci_11th_grade           -0.0033      0.014     -0.238      0.812        -0.030     0.024\n",
        "GPA_Math_11th_grade              0.0017      0.013      0.126      0.900        -0.024     0.028\n",
        "school_code_11th_grade        1.412e-05   6.97e-06      2.027      0.043      4.65e-07  2.78e-05\n",
        "exc_abs_11th_grade               0.1397      0.062      2.270      0.023         0.019     0.260\n",
        "unexc_abs_11th_grade             0.0655      0.018      3.550      0.000         0.029     0.102\n",
        "GPA_ENG_11th_grade              -0.0337      0.015     -2.194      0.028        -0.064    -0.004\n",
        "retained_in_11_majority_vote     0.8771      0.889      0.987      0.324        -0.865     2.619\n",
        "Num_Marks_11th_grade             0.5091      0.089      5.714      0.000         0.334     0.684\n",
        "GPA_Science_8th_grade            0.0061      0.020      0.303      0.762        -0.033     0.045\n",
        "GPA_8th_grade                   -0.0223      0.032     -0.696      0.487        -0.085     0.041\n",
        "GPA_SocSci_8th_grade            -0.0190      0.018     -1.065      0.287        -0.054     0.016\n",
        "GPA_Math_8th_grade               0.0127      0.019      0.672      0.502        -0.024     0.050\n",
        "school_code_8th_grade            0.0637      0.028      2.254      0.024         0.008     0.119\n",
        "exc_abs_8th_grade                0.0102      0.034      0.301      0.763        -0.056     0.077\n",
        "unexc_abs_8th_grade              0.0141      0.039      0.358      0.721        -0.063     0.091\n",
        "GPA_ENG_8th_grade               -0.0221      0.020     -1.093      0.275        -0.062     0.018\n",
        "retained_in_8_majority_vote     40.0174   2.24e+07   1.79e-06      1.000     -4.38e+07  4.38e+07\n",
        "Num_Marks_8th_grade             -0.4021      0.222     -1.813      0.070        -0.837     0.033\n",
        "GPA_Science_9th_grade            0.0128      0.012      1.086      0.277        -0.010     0.036\n",
        "GPA_9th_grade                   -0.0384      0.022     -1.716      0.086        -0.082     0.005\n",
        "GPA_SocSci_9th_grade             0.0111      0.012      0.919      0.358        -0.013     0.035\n",
        "GPA_Math_9th_grade              -0.0050      0.014     -0.365      0.715        -0.032     0.022\n",
        "school_code_9th_grade         3.996e-06   9.99e-06      0.400      0.689     -1.56e-05  2.36e-05\n",
        "exc_abs_9th_grade               -0.1461      0.061     -2.409      0.016        -0.265    -0.027\n",
        "unexc_abs_9th_grade             -0.0358      0.027     -1.317      0.188        -0.089     0.017\n",
        "GPA_ENG_9th_grade                0.0183      0.011      1.652      0.098        -0.003     0.040\n",
        "retained_in_9_majority_vote      1.4089      0.430      3.279      0.001         0.567     2.251\n",
        "Num_Marks_9th_grade             -0.2232      0.115     -1.939      0.052        -0.449     0.002\n",
        "GPA_Science_10th_grade          -0.0088      0.013     -0.696      0.486        -0.034     0.016\n",
        "GPA_10th_grade                  -0.0423      0.030     -1.405      0.160        -0.101     0.017\n",
        "GPA_SocSci_10th_grade            0.0160      0.015      1.057      0.291        -0.014     0.046\n",
        "GPA_Math_10th_grade              0.0069      0.012      0.559      0.576        -0.017     0.031\n",
        "school_code_10th_grade       -1.619e-06    6.8e-06     -0.238      0.812     -1.49e-05  1.17e-05\n",
        "exc_abs_10th_grade               0.0581      0.057      1.025      0.306        -0.053     0.169\n",
        "unexc_abs_10th_grade             0.0098      0.024      0.407      0.684        -0.037     0.057\n",
        "GPA_ENG_10th_grade               0.0258      0.013      1.955      0.051     -6.58e-05     0.052\n",
        "retained_in_10_majority_vote     0.2115      0.589      0.359      0.720        -0.944     1.367\n",
        "Num_Marks_10th_grade             0.1207      0.161      0.749      0.454        -0.195     0.436\n",
        "intercept                    -8297.5977   3679.568     -2.255      0.024     -1.55e+04 -1085.777\n",
        "================================================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 1282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_probs = logit_model.predict(imputed_testing_data[important_features + ['intercept']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data['log_{}_probs'.format(last_grade)] = pred_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data['log_{}_probs'.format(last_grade)].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1285,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x11e3560d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEBCAYAAACe6Rn8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGqVJREFUeJzt3W9sU3e+5/FPAjKsr5stUF3HQGd6S1GlxOMgpuoKlQdU\nkbaAVlUZkdBEhWoqJqsiJB4MV20pJrpKorlipB0eIFVleBDBw0QtKmKZTjdqGUUajVRZxFD+SCv2\nj1Zr53bY9ZDEaZL6nPuAi7/8SUztHHxOc96vJ/X51W5+/kD9sb92fBpc13UFAAilRr83AADwDyUA\nACFGCQBAiFECABBilAAAhBglAAAhtrzSv7x+/brOnDmjlpYW7d27V5J06dIlff7551q2bJn27Nmj\nZDIpScpmsxoeHpYkdXZ2PnYdAOC/iiUwNzenXbt26ebNm+W18+fP6/jx4/ruu+80MDCggYEBOY6j\noaEhpdNpSdLAwICSyeS8662trWpoaHiCdwkA8ENVLIFUKqVr1649sLZ+/Xpdu3ZNhUJBGzdulCTl\n83klEglFIhFJUjweVy6Xk+u6j6zfuy4AwH8VS2A+qVRKFy5c0Pfff6/XXntNkjQ5OaloNKrBwUFJ\nUjQa1cTERPnyw+uUAAAEQ1UlMD4+rkwmo/fee0+S1Nvbq1QqpVgspmKxqP3798t1XZ0+fVpNTU1y\nHGfedQBAMDy2BO7/aqFSqaRSqVRen52dlSQ1Nzcrl8uVr5fP59Xc3CzHceZdX8gf//hHLVu2rPp7\nAQAh9vTTT+vnP/95TbetWALnzp3T5cuXVSgUND09rZ6eHm3cuFG/+c1v5DiOXnvttfK8f/fu3err\n65MkdXR0SJIaGxvnXV/IsmXLtHnz5pruCACEVSaTqfm2DUH6FtGRkRFK4N+Mjo5q69atfm8jEMjC\nkIUhC5PJZNTe3l7Tbat+Y/hJG74y7uvP//m6Jv3D6n/n6x4AoF4C90rg/Yy/v0Nw5NXntG3DKl/3\nAADVWMwrAb42AgBCjBIIqNHRUb+3EBhkYcjCkIU3KAEACDFKIKD41IMhC0MWhiy8QQkAQIhRAgHF\nvNOQhSELQxbeoAQAIMQogYBi3mnIwpCFIQtvUAIAEGKUQEAx7zRkYcjCkIU3KAEACDFKIKCYdxqy\nMGRhyMIblAAAhBglEFDMOw1ZGLIwZOENSgAAQqziSWWuX7+uM2fOqKWlRXv37pUk3b59WydPnlSp\nVNKGDRv09ttvS5Ky2ayGh4clSZ2dnUomkxXXURnzTkMWhiwMWXijYgnMzc1p165dunnzZnnt7Nmz\nevPNN/Xiiy+W1xzH0dDQkNLptCRpYGBAyWRy3vXW1lY1NPh74hgAwF0Vx0GpVEqxWKx87DiOxsfH\nHygAScrn80okEopEIopEIorH48rlcvOu5/P5J3NPlhjmnYYsDFkYsvBGVecYvnPnjmZnZ3X8+HFN\nT09rx44devnllzU5OaloNKrBwUFJUjQa1cTERPnyw+uJRMLTOwEAqE1VJRCLxRSNRnX48GE5jqN0\nOq1NmzYpFoupWCxq//79cl1Xp0+fVlNTkxzHmXc9yIrTRUl3zzF875nGvdljPY+3bt3q68/nOLjH\n9wRlP34d31sLyn78Pq7VY080/8033yiTyZTfGD5x4oT27dun1atXK51OK51Oa/ny5ert7VU6nZbr\nuurv71dfX58cx5l3fSGcaB4AqreYE81XfCVw7tw5Xb58WYVCQdPT0+rp6dFbb72ljz/+WMViUVu2\nbFEkEpEk7d69u/wA39HRIUlqbGycdx2Pd/8znLAjC0MWhiy8UbEE3njjDb3xxhsPrD3zzDP64IMP\nHrluW1ub2trafvA6AMB//LJYQPEMx5CFIQtDFt6gBAAgxCiBgOIz0IYsDFkYsvAGJQAAIUYJBBTz\nTkMWhiwMWXiDEgCAEKMEAop5pyELQxaGLLxBCQBAiFECAcW805CFIQtDFt6gBAAgxCiBgGLeacjC\nkIUhC29QAgAQYpRAQDHvNGRhyMKQhTcoAQAIMUogoJh3GrIwZGHIwhuUAACEGCUQUMw7DVkYsjBk\n4Y2KZxa7fv26zpw5o5aWlvI5hiVpbm5Ohw4d0uuvv67t27dLkrLZrIaHhyVJnZ2dSiaTFdcBAP6r\n+Epgbm5Ou3btemT9iy++0PPPP18+dhxHQ0NDOnr0qI4ePaqhoaEF1x9zXnv8G+adhiwMWRiy8EbF\nEkilUorFYg+szczMKJvN6qWXXiqv5fN5JRIJRSIRRSIRxeNx5XK5edfz+fyTuScAgKpVHAfN5+LF\ni9q+fbsKhUJ5bXJyUtFoVIODg5KkaDSqiYmJ8uWH1xOJxOJ3vsQx7zRkYcjCkIU3qnpjuFgs6saN\nG9q0adMD67FYTMViUd3d3erq6tLU1JSampoWXA+y4nSxfHl0dPSBl5wcc8wxx0E9rlWD+5gh/Tff\nfKNMJqO9e/cqk8nowoULeuqpp/Ttt9+qVCrp4MGDWrt2rXp7e5VOp+W6rvr7+9XX1yfHceZdX8jI\nyIjezzQs+k4txpFXn9O2Dat83YN09w+YZzp3kYUhC0MWJpPJqL29vabbVhwHnTt3TpcvX1ahUND0\n9LR6enq0efNmSdJXX32lmZkZrV+/XpK0e/fu8gN8R0eHJKmxsXHedQBAMDz2lUA98UoAAKq3mFcC\n/LIYAIQYJRBQXrzhs1SQhSELQxbeoAQAIMQogYDiUw+GLAxZGLLwBiUAACFGCQQU805DFoYsDFl4\ngxIAgBCjBAKKeachC0MWhiy8QQkAQIhRAgHFvNOQhSELQxbeoAQAIMQogYBi3mnIwpCFIQtvUAIA\nEGKUQEAx7zRkYcjCkIU3KAEACDFKIKCYdxqyMGRhyMIblAAAhFjF00tev35dZ86cUUtLi/bu3StJ\nOnXqlHK5nBzH0YEDBxSPxyVJ2WxWw8PDkqTOzk4lk8mK66iM86casjBkYcjCGxVLYG5uTrt27dLN\nmzfLaz09PZKkq1ev6rPPPtOvfvUrOY6joaEhpdNpSdLAwICSyeS8662trWpo8PcUkgCAuyqOg1Kp\nlGKx2Lz/buXKlVq+/G6H5PN5JRIJRSIRRSIRxeNx5XK5edfz+bz392IJ4hmOIQtDFoYsvFHxlUAl\nX375pXbu3ClJmpycVDQa1eDgoCQpGo1qYmKifPnh9UQisbhdAwA8UVMJfP3111q7dq3WrVsnSYrF\nYioWi9q/f79c19Xp06fV1NQkx3HmXQ+y4nRR0ipJ9jnke8846nl8/2eg/fj5QTp+OBO/9+Pn8ZUr\nV/Tuu+8GZj9+Hn/00Uf62c9+Fpj9+H1cqwbXdd1KV/jmm2+UyWTKbwzfunVLo6Oj2rdvX/k6juOo\nt7dX6XRaruuqv79ffX19C64vZGRkRO9n/H2/4Mirz2nbhlW+7kHiTa/7kYUhC0MWJpPJqL29vabb\nViyBc+fO6fLlyyoUCmppaVFPT48OHjyoNWvWqLGxUc8++6zeeecdSdLY2Fj5U0AdHR1KpVIV1+dD\nCQBA9Z5YCdQbJQAA1VtMCfDLYgHF96IYsjBkYcjCG5QAAIQYJRBQvOFlyMKQhSELb1ACABBilEBA\nMe80ZGHIwpCFNygBAAgxSiCgmHcasjBkYcjCG5QAAIQYJRBQzDsNWRiyMGThDUoAAEKMEggo5p2G\nLAxZGLLwBiUAACFGCQQU805DFoYsDFl4gxIAgBCjBAKKeachC0MWhiy8QQkAQIhVLIHr16/rgw8+\n0NmzZ8tr2WxWx44d07Fjx3T16tWa11EZ805DFoYsDFl4o+KJ5ufm5rRr1y7dvHlT0t1zCQ8NDSmd\nTkuSBgYGlEwmq1pvbW1VQ4O/Zw8DANxVsQRSqZSuXbtWPs7n80okEopEIpKkeDyuXC4n13V/8Pq9\n/wYqY95pyMKQhSELb1QsgYdNTk4qGo1qcHBQkhSNRjUxMVG+/EPXKQEACIaq3hiOxWIqFovq7u5W\nV1eXpqam1NTUVPU6Ho95pyELQxaGLLzx2FcCruuWLzc3NyuXy5WP8/m8mpub5ThOVetBVpwuSlol\nyf6S3XvZybE/x/cEZT9+Hl+5ciVQ+/Hz+MqVK4Haj9/HtWpw73+Uf8i5c+d0+fJlFQoFtbS0qKen\nR2NjYxoeHpYkdXR0KJVKSVLV6/MZGRnR+xl/3zQ+8upz2rZhla97AIBqZDIZtbe313TbiiVQb5QA\nAFRvMSXAL4sFFPNOQxaGLAxZeIMSAIAQowQCis9AG7IwZGHIwhuUAACEGCUQUMw7DVkYsjBk4Q1K\nAABCjBIIKOadhiwMWRiy8AYlAAAhRgkEFPNOQxaGLAxZeIMSAIAQowQCinmnIQtDFoYsvEEJAECI\nUQIBxbzTkIUhC0MW3qAEACDEKIGAYt5pyMKQhSELb1ACABBilEBAMe80ZGHIwpCFNx57juGFXLp0\nSZ9//rmWLVumPXv2KJlMKpvNlk8l2dnZqWQyKUkLrgMA/FVzCZw/f17Hjx/Xd999p4GBAfX392to\naEjpdFqSNDAwoGQyKcdxHllvbW1VQ4O/p5EMOuadhiwMWRiy8EbNJbB+/Xpdu3ZNhUJBGzduVC6X\nUyKRUCQSkSTF43Hlcjm5rvvIej6fVyKR8OYeAABqVvN7AqlUShcuXNCf/vQnJZNJTU5OKhqNanBw\nUIODg4pGo5qYmFhwHZUx7zRkYcjCkIU3aiqB8fFxZTIZvffeezpy5IjOnz+vFStWqFgsqru7W11d\nXZqamlJTU5Nisdi86wAA/9U0DnIcR6VSSZLkuq5mZ2fV3NysXC5Xvk4+n1dzc7Mcx5l3PaiK00VJ\nqyTZM417s8d6Hm/dutXXn89xcI/vCcp+/Dq+txaU/fh9XKsG13XdWm74ySef6ObNm3IcR6+88oq2\nbdumsbGx8qeAOjo6lEqlJGnB9YeNjIzo/Yy/bxgfefU5bduwytc9AEA1MpmM2tvba7ptzW8M/+IX\nv3hkra2tTW1tbT94HQu7/xlO2JGFIQtDFt7gl8UAIMQogYDiGY4hC0MWhiy8QQkAQIhRAgHFZ6AN\nWRiyMGThDUoAAEKMEggo5p2GLAxZGLLwBiUAACFGCQQU805DFoYsDFl4gxIAgBCjBAKKeachC0MW\nhiy8QQkAQIhRAgHFvNOQhSELQxbeoAQAIMQogYBi3mnIwpCFIQtvUAIAEGKUQEAx7zRkYcjCkIU3\nKAEACLGazyx2+/ZtnTx5UqVSSS+88IL27dunbDZbPo1kZ2enksmkJC24joUx7zRkYcjCkIU3ai6B\ns2fP6s0339SLL74o6e7J54eGhpROpyVJAwMDSiaT8663traqocHfcwkDAGocBzmOo/Hx8XIBSFI+\nn1cikVAkElEkElE8Hlcul5t3PZ/Pe3YHlirmnYYsDFkYsvBGTa8E7ty5o9nZWR0/flzT09PasWOH\nnn76aUWjUQ0ODkqSotGoJiYmypcfXk8kEp7cAQBA7Wp6JRCLxRSNRnX48GF9+OGH+vTTT7VixQoV\ni0V1d3erq6tLU1NTampqUiwWm3c9qIrTxfLl0dHRB55t1PN469atvv78IB3fm/0GZT9+Ht8vCPvx\n8/jhTPzej9/HtWpwXdet5YYnTpzQvn37tHr1aqXTaR09elT9/f1Kp9NyXVf9/f3q6+uT4zjq7e19\nZH0+IyMjej/j73sFR159Tts2rPJ1DwBQjUwmo/b29ppuW/Mbw2+99ZY+/vhjFYtFbdmyRStWrNDu\n3bvLD/AdHR2SpMbGxnnXUdn9z4DDjiwMWRiy8EbNJfDMM8/ogw8+eGCtra1NbW1tj1x3oXUAgL/4\nZbGA4hmOIQtDFoYsvEEJAECIUQIB5cW7/ksFWRiyMGThDUoAAEKMEggo5p2GLAxZGLLwBiUAACFG\nCQQU805DFoYsDFl4gxIAgBCjBAKKeachC0MWhiy8QQkAQIhRAgHFvNOQhSELQxbeoAQAIMQogYBi\n3mnIwpCFIQtvUAIAEGKUQEAx7zRkYcjCkIU3KAEACDFKIKCYdxqyMGRhyMIbNZ9ZTJLm5uZ06NAh\nvf7669q+fbuy2ayGh4clSZ2dnUomk5K04DoAwF+LeiXwxRdf6Pnnn1dDQ4Nc19XQ0JCOHj2qo0eP\namhoSJLkOM4j6zWe2z5UmHcasjBkYcjCGzWXwMzMjLLZrF566SW5rqtcLqdEIqFIJKJIJKJ4PK5c\nLqd8Pv/Iej6f9/I+AABqVPM46OLFi9q+fbsKhYIkaXJyUtFoVIODg5KkaDSqiYmJ8uWH1xOJxOJ2\nvsQx7zRkYcjCkIU3anolUCwWdePGDW3atKm8FovFVCwW1d3dra6uLk1NTampqWnB9aAqThfLl0dH\nRx94yckxxxxzHNTjWjW4NQzoM5mMLly4oKeeekrffvutSqWS3n33XZ0+fVrpdFqu66q/v199fX1y\nHEe9vb2PrM9nZGRE72caFn2nFuPIq89p24ZVvu5BuvsHzDOdu8jCkIUhC5PJZNTe3l7TbWsaB23e\nvFmbN2+WJH311VeamZnRT3/6U+3evbv8AN/R0SFJamxsnHcdAOC/ml4JPCm8EgCA6i3mlQC/LAYA\nIUYJBJQXb/gsFWRhyMKQhTcoAQAIMUogoPjUgyELQxaGLLxBCQBAiFECAcW805CFIQtDFt6gBAAg\nxCiBgGLeacjCkIUhC29QAgAQYpRAQDHvNGRhyMKQhTcoAQAIMUogoJh3GrIwZGHIwhuUAACEGCUQ\nUMw7DVkYsjBk4Q1KAABCjBIIKOadhiwMWRiy8AYlAAAhVtPpJU+dOqVcLifHcXTgwAHF43Fls1kN\nDw9Lkjo7O5VMJiVpwXVUxvlTDVkYsjBk4Y2aSqCnp0eSdPXqVX322Wfav3+/hoaGlE6nJUkDAwNK\nJpNyHOeR9dbWVjU0+HsKSQDAXTWVwD0rV67U8uXLlcvllEgkFIlEJEnxeFy5XE6u6z6yns/nlUgk\nFr/zJY5nOIYsDFkYsvDGokrgyy+/1M6dOzU5OaloNKrBwUFJUjQa1cTERPnyw+uUAAAEQ81vDH/9\n9ddau3at1q1bp1gspmKxqO7ubnV1dWlqakpNTU0LrgdZcbpYvjw6OvrAZ5HreXzvsl8/P0jHD2fi\n9378PP7oo48CtR8/jz/66KNA7cfv41o1uK7rVnujW7duaXR0VPv27ZMkOY6j3t5epdNpua6r/v5+\n9fX1Lbi+kJGREb2f8ff9giOvPqdtG1b5ugeJN73uRxaGLAxZmEwmo/b29ppuW1MJHDx4UGvWrFFj\nY6N+8pOf6Je//KXGxsbKnwLq6OhQKpWSpAXX50MJAED1FlMCNb0ncPLkyUfW2tra1NbW9oPXAQD+\n45fFAsqLWd9SQRaGLAxZeIMSAIAQowQCije8DFkYsjBk4Q1KAABCjBIIKOadhiwMWRiy8AYlAAAh\nRgkEFPNOQxaGLAxZeIMSAIAQowQCinmnIQtDFoYsvEEJAECIUQIBxbzTkIUhC0MW3qAEACDEKIGA\nYt5pyMKQhSELbyzqzGJLVe7OjP5lctbXPfzd3z/r688HEA6UwDz+ZXJW//hf/7uve/jtzhd8/flB\nwuzXkIUhC28wDgKAEKtbCWSzWR07dkzHjh3T1atX6/Vjf7T+9re/+b2FwGD2a8jCkIU36jIOchxH\nQ0NDSqfTkqSBgQG1traqocHfU0kCQNjVpQTy+bwSiYQikYgkKR6Pl9cwv9Wr/r3G/u+E39vQ38ci\nSjSt8HUPzH4NWZggZBGED5EsVl1KYHJyUtFoVIODg5KkaDSqiYkJSqCCv31X0j/9t//h9zb0X/7T\nC77/JQ9CEQHzCcKHSCTpnzfXftu6lEAsFlOxWNT+/fvluq5Onz6tpqamea/7n//DunpsaUE/XbVS\nd7773tc9SNL33/u/BykYZfTP//EnvheRJMUiyzQ5W/J1D42lGTnL/C9EsrhrtuT4+vO9UJcSaG5u\nVi6XKx/n83k1Nzc/cr2nn35a/1D4P/XY0oL+//+8+8/FNKsn7vxv//cgSf/vlv/7+Ov/kr8PN3cF\n4a36IOQgkcU9yxSAxwrdfeysVYPruq6He1nQ2NiYhoeHJUkdHR1KpVL1+LEAgArqVgIAgODhl8UA\nIMQoAQAIMUoAAEKs7l8gl81my28Qd3Z2KplMenLdH6Nq7t+pU6eUy+XkOI4OHDigeDxer23WRbV/\n1nNzczp06JBef/11bd++vR5brJtqsrh9+7ZOnjypUqmkDRs26O23367XNuuimiwuXbqkzz//XMuW\nLdOePXuW1OPF9evXdebMGbW0tGjv3r0Vr1v146ZbR6VSyT169Kg7MzPjzszMuMeOHXMdx1n0dX+M\nar1/V65ccU+dOlWHHdZPLVlcuHDB/e1vf+v+4Q9/qNMu66PaLH73u9+5N27cqOMO66faLH7961+7\npVLJnZqaco8cOVLHnT55Y2Nj7l/+8hf3zJkzFa9Xy/9LdR0H3f/1EZFIpPz1EYu97o9Rrfdv5cqV\nWr58aX0DeLVZzMzMKJvN6qWXXpK7xD7cVk0WjuNofHxcL774Yp13WR/V/r1Yv369rl27pkwmo40b\nN9Zxp09eKpVSLBZ77PVqeVyp66NJNV8fsdS/aqLW+/fll19q586dddhh/VSbxcWLF7V9+3YVCoU6\n7rI+qsnizp07mp2d1fHjxzU9Pa0dO3bo5ZdfrvOOn5xq/16kUilduHBB33//vV577bU67jQ4anlc\nqesrgXtfH9Hd3a2uri5NTU0t+PUR1Vz3x6iW+/f1119r7dq1WrfO36/W8Fo1WRSLRd24cUObNm2q\n8y7ro9r/R6LRqA4fPqwPP/xQn376qWZn/f96Da9Uk8X4+LgymYzee+89ffjhhzp//vySyuKHquVx\npa6vBH7o10dUe90fo2rv361bt3Tt2jXt27evHturq2qyuHHjhubm5nTixAl9++23KpVKSiaTWr9+\nfb22+0RVk8Xy5cu1Zs0aFQoFrV69esmNCavJwnEclUp3v0jCdd0lWQA/ZPRZy+Nm3X9jeKGvj/jz\nn/+sFStWaPPmzY+97lJRTRYHDx7UmjVr1NjYqGeffVbvvPOOL3t+UqrJ4p6vvvpKMzMzS+6lfzVZ\n/PWvf9Xvf/97FYtFbdmyZcmNCqvJ4pNPPtHNmzflOI5eeeUVbdu2zY8tPxHnzp3T5cuXVSgU1NLS\nop6eHknePG7ytREAEGL8shgAhBglAAAhRgkAQIhRAgAQYpQAAIQYJQAAIUYJAECIUQIAEGL/Cpq/\nn5RYrgPBAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11e16f750>"
       ]
      }
     ],
     "prompt_number": 1285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_students = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_testing_data.sort('log_{}_probs'.format(last_grade), ascending=False)[:num_students][outcome_col].value_counts(normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1301,
       "text": [
        "1    0.5\n",
        "0    0.5\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 1301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Feature Importance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_grade = 8\n",
      "exclude_grades = range(8, last_grade+1)\n",
      "exclude_student_ids = dropout_data[dropout_data['Grade'].isin(exclude_grades)]['External_Student_ID'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1444
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = renamed_a[renamed_a['GPA_{}th_grade'.format(last_grade)].notnull()\n",
      "                             & ~(renamed_a['External_Student_ID'].isin(exclude_student_ids)) \n",
      "                             & (renamed_a['transferred_out_before_graduating'] == 0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1445
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = tree.DecisionTreeClassifier(criterion='gini')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1446
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outcome_col = 'fail_to_finish_high_school_in_4_years'\n",
      "feature_cols = []\n",
      "for year in range(8, last_grade+1):\n",
      "    feature_cols += [\n",
      "#                      'CITY_{}th_grade'.format(year),\n",
      "                     'GPA_{}th_grade'.format(year),\n",
      "                     'GPA_ENG_{}th_grade'.format(year),\n",
      "                     'GPA_Math_{}th_grade'.format(year),\n",
      "                     'GPA_Science_{}th_grade'.format(year),\n",
      "                     'GPA_SocSci_{}th_grade'.format(year),\n",
      "#                      'Grade_{}th_grade'.format(year),\n",
      "                     'NumAdvanced_{}th_grade'.format(year),\n",
      "                     'NumAdvanced_ENG_{}th_grade'.format(year),\n",
      "                     'NumAdvanced_Math_{}th_grade'.format(year),\n",
      "                     'NumAdvanced_Science_{}th_grade'.format(year),\n",
      "                     'NumAdvanced_SocSci_{}th_grade'.format(year),\n",
      "                     'Num_ENG_{}th_grade'.format(year),\n",
      "                     'Num_Marks_{}th_grade'.format(year),\n",
      "                     'Num_Math_{}th_grade'.format(year),\n",
      "                     'Num_Science_{}th_grade'.format(year),\n",
      "                     'Num_SocSci_{}th_grade'.format(year),\n",
      "#                      'STATE_{}th_grade'.format(year),\n",
      "#                      'Street_{}th_grade'.format(year),\n",
      "                     'ZIP_{}th_grade'.format(year),\n",
      "                     'daysabs_{}th_grade'.format(year),\n",
      "                     'eds_{}th_grade'.format(year),\n",
      "                     'ethnic_{}th_grade'.format(year),\n",
      "                     'exc_abs_{}th_grade'.format(year),\n",
      "#                      'grade_{}th_grade'.format(year),\n",
      "                     'lep_{}th_grade'.format(year),\n",
      "                     'reporting_year_{}th_grade'.format(year),\n",
      "                     'retained_in_{}_majority_vote'.format(year),\n",
      "                     'school_code_{}th_grade'.format(year),\n",
      "                     'sex_{}th_grade'.format(year),\n",
      "                     'swd_{}th_grade'.format(year),\n",
      "                     'times_tardy_{}th_grade'.format(year),\n",
      "                     'unexc_abs_{}th_grade'.format(year)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1447
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data = model_data.fillna(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = preprocess(model_data[feature_cols + [outcome_col]], outcome_col\n",
      "                  , doFeatureSelection=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1449
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1450
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_features, sorted_importances = get_feature_importances(clf, feature_cols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature Importances:\n",
        "----------\n",
        "1. GPA_8th_grade - 0.329\n",
        "2. exc_abs_8th_grade - 0.105\n",
        "3. GPA_ENG_8th_grade - 0.092\n",
        "4. GPA_Science_8th_grade - 0.082\n",
        "5. daysabs_8th_grade - 0.077\n",
        "6. GPA_SocSci_8th_grade - 0.061\n",
        "7. school_code_8th_grade - 0.058\n",
        "8. unexc_abs_8th_grade - 0.042\n",
        "9. GPA_Math_8th_grade - 0.040\n",
        "10. Num_Marks_8th_grade - 0.034\n",
        "11. ZIP_8th_grade - 0.028\n",
        "12. retained_in_8_majority_vote - 0.017\n",
        "13. ethnic_8th_grade - 0.013\n",
        "14. swd_8th_grade - 0.007\n",
        "15. Num_Science_8th_grade - 0.006\n",
        "16. eds_8th_grade - 0.003\n",
        "17. Num_SocSci_8th_grade - 0.003\n",
        "18. Num_Math_8th_grade - 0.003\n",
        "19. Num_ENG_8th_grade - 0.001\n",
        "20. NumAdvanced_8th_grade - 0.000\n",
        "21. sex_8th_grade - 0.000\n",
        "22. lep_8th_grade - 0.000\n",
        "23. NumAdvanced_ENG_8th_grade - 0.000\n",
        "24. NumAdvanced_Math_8th_grade - 0.000\n",
        "25. NumAdvanced_Science_8th_grade - 0.000\n",
        "26. times_tardy_8th_grade - 0.000\n",
        "27. reporting_year_8th_grade - 0.000\n",
        "28. NumAdvanced_SocSci_8th_grade - 0.000\n"
       ]
      }
     ],
     "prompt_number": 1451
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_data['times_tardy_8th_grade'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1452,
       "text": [
        "0    1731\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 1452
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1452
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}